[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n          Introduction to Programming for PhD students in Education, Harvard University\n      ",
    "section": "",
    "text": "Programming, Tools, R, Stata, and More\n      \n      \n          EDU • Spring 2024HGSE, Harvard University"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/01-basics.html",
    "href": "content/01-basics.html",
    "title": "Introduction to R: The Basics",
    "section": "",
    "text": "Welcome to this introductory tutorial on R! R is a powerful language and environment for statistical computing and graphics. It offers a wide variety of statistical and graphical techniques and is highly extensible. One of the key features of R is its package ecosystem, the most notable of which is the tidyverse, a collection of packages designed for data science.\nThis tutorial is designed for individuals with minimal statistical background. We will cover the basics of R, including how to install and load packages, import data, perform simple data manipulations, and create basic visualizations."
  },
  {
    "objectID": "content/01-basics.html#installing-r-and-rstudio",
    "href": "content/01-basics.html#installing-r-and-rstudio",
    "title": "Introduction to R: The Basics",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\nBefore we begin, you need to have R and RStudio installed on your computer. R is the underlying statistical computing environment, while RStudio provides a convenient and powerful user interface.\n\nDownload R from The Comprehensive R Archive Network (CRAN).\nDownload RStudio from RStudio’s website."
  },
  {
    "objectID": "content/01-basics.html#getting-started",
    "href": "content/01-basics.html#getting-started",
    "title": "Introduction to R: The Basics",
    "section": "Getting Started",
    "text": "Getting Started\n\nSetting Up Your Environment\nOpen RStudio and let’s get started by installing and loading the tidyverse package:\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nThe first line will install the package, and the second will load the package to your current R session. After you install your package, you do not need to use the first line again in your scripts."
  },
  {
    "objectID": "content/01-basics.html#basic-r-operations",
    "href": "content/01-basics.html#basic-r-operations",
    "title": "Introduction to R: The Basics",
    "section": "Basic R Operations",
    "text": "Basic R Operations\nNow, let’s look at the basic operations. First, R can be used as a simple calculator. Try typing 2 + 2 in the console. You can assign values to variables using &lt;-.\n\nx &lt;- 2 + 2\nx\n\n[1] 4"
  },
  {
    "objectID": "content/01-basics.html#vectors-and-data-frames",
    "href": "content/01-basics.html#vectors-and-data-frames",
    "title": "Introduction to R: The Basics",
    "section": "Vectors and Data Frames",
    "text": "Vectors and Data Frames\nVectors are basic data structures in R that contain elements of the same type. Use the c() function to create a vector:\n\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nmy_vector\n\n[1] 1 2 3 4 5\n\n\nA data frame is a table or a two-dimensional array-like structure. Let’s create a simple data frame:\n\nmy_data_frame &lt;- data.frame(\n  id = 1:5,\n  name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\", \"Alex\"),\n  score = c(90, 80, 88, 100, 100)\n)\n\nmy_data_frame\n\n  id   name score\n1  1   Emma    90\n2  2   Rony    80\n3  3 Jostin    88\n4  4  David   100\n5  5   Alex   100"
  },
  {
    "objectID": "content/01-basics.html#importing-data",
    "href": "content/01-basics.html#importing-data",
    "title": "Introduction to R: The Basics",
    "section": "Importing Data",
    "text": "Importing Data\nR can read data from various sources. The read_csv() function from the readr package (part of the tidyverse) is commonly used for reading CSV files:\n\nmy_data &lt;- read_csv(\"path/to/your/file.csv\")\n\nReplace \"path/to/your/file.csv\" with the actual file path to a csv file."
  },
  {
    "objectID": "content/01-basics.html#data-manipulation-with-dplyr",
    "href": "content/01-basics.html#data-manipulation-with-dplyr",
    "title": "Introduction to R: The Basics",
    "section": "Data Manipulation with dplyr",
    "text": "Data Manipulation with dplyr\nThe dplyr package offers a set of functions for manipulating data frames. You do not have to load this package since it is already loaded within the tidyverse package.\nLet’s look at the following functions:\n\nfilter(): Extracts a subset of rows based on conditions.\nselect(): Selects columns by name.\nmutate(): Creates new columns or modifies existing ones.\nsummarize(): Summarizes multiple values into a single value.\n\nImage that I would like to have a filtered dataset that contains observations with scores higher than 85. I can run the following:\n\nfiltered_data &lt;- my_data_frame %&gt;%\n  filter(score &gt; 85) %&gt;%\n  select(name, score)\n\nIn this example:\n\nmy_data_frame is passed as the first argument to the filter() function, which filters rows where score &gt; 85.\nThe result of filter() is then passed as the first argument to select(), which keeps only the columns name and score.\nThe final result is assigned to filtered_data.\n\nBenefits of Using the Pipe Operator\n\nReadability: The flow of operations is from left to right, similar to how we read text, making the code easier to follow.\nMaintainability: It’s easier to add or remove steps in the data processing pipeline without having to rewrite function calls or manage temporary variables.\nClarity: Each step in the pipeline can be clearly seen, making it easier to understand what each part of the code is doing.\n\nThe pipe operator is a cornerstone of the tidyverse approach to data manipulation, enabling clear and expressive code that closely resembles natural language. As you become more familiar with R and the tidyverse, you’ll find the pipe operator indispensable for efficient data analysis and transformation.\n\nMutate, Summarize, and other Functions\nThe mutate() function allows you to create new columns in your data frame or change existing ones based on some operations or functions applied to the data. It’s particularly useful for feature engineering, calculating new metrics, or preparing your data for analysis.\nLet’s say we have a data frame my_data_frame that contains student IDs, names, and scores. We want to add a new column that shows whether each student passed based on their score, with a score of 85 or above considered a pass.\n\n# Add a new column 'passed' with boolean values: TRUE if score &gt;= 85, FALSE otherwise\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(passed = score &gt;= 85)\n\nmy_data_frame\n\n  id   name score passed\n1  1   Emma    90   TRUE\n2  2   Rony    85   TRUE\n3  3 Jostin    88   TRUE\n\n\nThis will add a new column passed to my_data_frame, where each row will have TRUE if the student’s score is 85 or higher, and FALSE otherwise.\nSuppose you want to standardize the scores (subtract the mean and divide by the standard deviation) for analysis.\n\n# Standardize the 'score' column\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    score_standardized = (score - mean(score)) / sd(score)\n  )\n\nmy_data_frame\n\n  id   name score passed score_standardized\n1  1   Emma    90   TRUE          0.9271726\n2  2   Rony    85   TRUE         -1.0596259\n3  3 Jostin    88   TRUE          0.1324532\n\n\nThis operation creates a new column score_standardized where each student’s score is standardized.\n\n\nUsing Multiple mutate() Operations\nYou can chain multiple operations within a single mutate() call. For example, if you wanted to add a column for the grade (A, B, C, etc.) based on the standardized score, you could do it within the same mutate():\n\n# Add a grade column based on standardized scores\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    score_standardized = (score - mean(score)) / sd(score),\n    grade = case_when(\n      score_standardized &gt;= 1  ~ \"A\",\n      score_standardized &gt;= 0  ~ \"B\",\n      score_standardized &lt; 0   ~ \"C\"\n    )\n  )\n\nmy_data_frame\n\n  id   name score passed score_standardized grade\n1  1   Emma    90   TRUE          0.9271726     B\n2  2   Rony    85   TRUE         -1.0596259     C\n3  3 Jostin    88   TRUE          0.1324532     B\n\n\nHere, case_when() is used to assign grades: “A” for standardized scores &gt;= 1, “B” for scores &gt;= 0 and &lt; 1, and “C” for scores &lt; 0. This illustrates how mutate() can be used to perform multiple transformations simultaneously, enhancing the readability and efficiency of your data manipulation code."
  },
  {
    "objectID": "content/01-basics.html#summarizing-data-with-summarise",
    "href": "content/01-basics.html#summarizing-data-with-summarise",
    "title": "Introduction to R: The Basics",
    "section": "Summarizing Data with summarise()",
    "text": "Summarizing Data with summarise()\nThe summarise() function in dplyr is used to create summary statistics for a dataset or subsets of a dataset. This function can be particularly powerful when combined with group_by(), which groups the data frame by one or more variables.\n\nBasic Usage of summarise()\nHere’s how you can use summarise() to calculate the average (mean) score of all students in my_data_frame:\n\naverage_score &lt;- my_data_frame %&gt;%\n  summarise(\n    mean_score = mean(score)\n  )\n\naverage_score\n\n  mean_score\n1   87.66667\n\n\nThis code calculates the mean of the score column and stores the result in a new data frame called average_score with a single column mean_score.\n\n\nGrouped Summaries\nTo calculate the average score by a categorical variable (e.g., by a hypothetical class column), you first group the data by that variable using group_by(), then apply summarise():\nFirst, let’s add a hypothetical class variable to our data frame to categorize students into two classes, “A” and “B”. We’ll use the mutate() function to accomplish this:\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    class = if_else(id %% 2 == 0, \"A\", \"B\")\n  )\n\nmy_data_frame\n\n  id   name score passed score_standardized grade class\n1  1   Emma    90   TRUE          0.9271726     B     B\n2  2   Rony    85   TRUE         -1.0596259     C     A\n3  3 Jostin    88   TRUE          0.1324532     B     B\n\n\nThis code adds a new column class to my_data_frame, where students with an even id are assigned to class “A” and students with an odd id are assigned to class “B”.\nNow that we have a class variable, we can calculate the average score for each class:\n\naverage_score_by_class &lt;- my_data_frame %&gt;%\n  group_by(class) %&gt;%\n  summarise(mean_score = mean(score))\n\naverage_score_by_class\n\n# A tibble: 2 × 2\n  class mean_score\n  &lt;chr&gt;      &lt;dbl&gt;\n1 A             85\n2 B             89\n\n\nThis will calculate the mean score for each class separately.\n\n\nMultiple Summary Functions\nYou can also use summarise() to apply multiple summary functions at once. For example, to calculate the mean, median, and standard deviation of scores:\n\nsummary_statistics &lt;- my_data_frame %&gt;%\n  summarise(\n    mean_score = mean(score),\n    median_score = median(score),\n    sd_score = sd(score)\n  )\n\nsummary_statistics\n\n  mean_score median_score sd_score\n1   87.66667           88 2.516611\n\n\n\n\nUsing summarise() with mutate()\nWhile summarise() reduces your data to a single summary row, mutate() can be used alongside to add summary columns to the original data frame. For example, adding a column with the mean score to each row:\n\nmy_data_frame_with_mean &lt;- my_data_frame %&gt;%\n  mutate(mean_score = mean(score))\n\nmy_data_frame_with_mean\n\n  id   name score passed score_standardized grade class mean_score\n1  1   Emma    90   TRUE          0.9271726     B     B   87.66667\n2  2   Rony    85   TRUE         -1.0596259     C     A   87.66667\n3  3 Jostin    88   TRUE          0.1324532     B     B   87.66667"
  },
  {
    "objectID": "content/01-basics.html#data-visualization-with-ggplot2",
    "href": "content/01-basics.html#data-visualization-with-ggplot2",
    "title": "Introduction to R: The Basics",
    "section": "Data Visualization with ggplot2",
    "text": "Data Visualization with ggplot2\nggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics.\n\nBasics of ggplot2\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\nCreating a Scatter Plot\nLet’s create a simple scatter plot to visualize the relationship between two variables in my_data_frame.\n\nggplot(my_data_frame, aes(x = id, y = score)) +\n  geom_point()\n\n\n\n\nIn this example, ggplot() initializes the plot with the data frame my_data_frame, and aes(x = id, y = score) specifies that id should be on the x-axis and score on the y-axis. geom_point() adds points to represent each row in the dataset.\n\n\nCustomizing Your Plot\nggplot2 offers extensive customization options. For example, you can add titles and labels, change the theme, and modify the color of the points.\n\nggplot(my_data_frame, aes(x = id, y = score)) +\n  geom_point(color = \"blue\") +\n  labs(title = \"Student Scores\", x = \"ID\", y = \"Score\") +\n  theme_minimal()\n\n\n\n\nThis adds a title to the plot, labels the x and y axes, changes the point color to blue, and applies a minimal theme for a cleaner look.\n\n\nCreating a Bar Chart\nTo create a bar chart showing students by score, you can use geom_col().\n\nggplot(my_data_frame, aes(y = score, x = as.factor(name))) +\n  geom_col(color = \"black\", fill = \"grey\") +\n  labs(title = \"Students by Score\", x = NULL, y = \"Score\") +\n  theme_minimal()\n\n\n\n\nHere, as.factor(name) is used to treat the name variable as a categorical variable. geom_bar() by default counts the number of occurrences of each unique value.\nggplot2 is a versatile and powerful tool for creating visualizations in R. With its consistent syntax and comprehensive features, it allows you to construct a wide variety of graph types, from simple scatter plots to complex multi-layered graphics. As you become more familiar with ggplot2, you will discover its full potential for conveying information in a visual format.\nCertainly! Let’s add a section on the summarise() function from the dplyr package. summarise() is used to reduce each group of a data frame to a single summary value, making it essential for data analysis tasks such as calculating summaries (mean, median, sum, etc.) across groups."
  },
  {
    "objectID": "index.html#about-this-project",
    "href": "index.html#about-this-project",
    "title": "\n          Introduction to Programming for PhD students in Education, Harvard University\n      ",
    "section": "About This Project",
    "text": "About This Project\nThis project is a work in progress, and I am constantly looking to update and improve the content. I welcome any suggestions, feedback, or contributions you might have."
  },
  {
    "objectID": "index.html#tutorials",
    "href": "index.html#tutorials",
    "title": "\n          Introduction to Programming for PhD students in Education, Harvard University\n      ",
    "section": "Tutorials",
    "text": "Tutorials\nI’ve crafted these tutorials to cater to a broad spectrum of needs, from the basics of statistical analysis using R, to more nuanced discussions on quantitative research methodologies. Here are a few highlights:\n\nTo complete"
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "\n          Introduction to Programming for PhD students in Education, Harvard University\n      ",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nTo complete\n\nThank you for visiting, and I hope you find these resources helpful on your academic path!"
  },
  {
    "objectID": "index.html#lets-collaborate",
    "href": "index.html#lets-collaborate",
    "title": "Welcome Intro to R for PhD Students in Education",
    "section": "Let’s Collaborate",
    "text": "Let’s Collaborate\nI am the sole author and creator behind this project, and it is a labor of love. I am always open to suggestions for new content, improvements to existing materials, or any other feedback you might have. If you’d like to contribute or share your thoughts, please feel free to contact me.\nThank you for visiting, and I hope you find these resources helpful on your academic path!\n\n\n© 2024 Rony Rodriguez-Ramirez"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings, lectures, and videos",
    "section": "",
    "text": "Each tutorial has a set of required readings that you should complete before watching the lecture."
  },
  {
    "objectID": "content/02-data-cleaning.html",
    "href": "content/02-data-cleaning.html",
    "title": "Data Cleaning with the tidyverse",
    "section": "",
    "text": "Building on the basics of R and the tidyverse, this tutorial delves into more complex data cleaning and analysis techniques. We’ll tackle common challenges encountered with real-world data and explore ways to manipulate and analyze datasets to extract meaningful insights. But first, let’s see some differences between some data frames:\n\n\nIn the tidyverse, tibble() and tribble() are functions that create a more modern take on the data frame. They are part of the tibble package and offer several advantages over the base R data.frame for data analysis and manipulation (the one we saw in the basics tutorial. Here’s a brief overview of each and how they compare to traditional data frames.\n\n\n\nA tibble is a modern reimagining of the data frame, keeping what time has proven to be effective, and throwing out what is not. Here are some key features:\n\nPrinting: Tibbles are printed in a more readable format than traditional data frames, showing only the first 10 rows and all columns that fit on the screen.\nSubsetting: Subsetting a tibble with [ always returns a tibble, unlike data.frame, which might return a vector if a single column is selected.\nColumn data types: Tibbles are more tolerant about column types and do not convert strings to factors by default (a common source of frustration in R).\n\n\n# Creating a tibble\nmy_tibble &lt;- tibble(\n  id = 1:5,\n  name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\", \"Alex\"),\n  score = c(90, 80, 88, 100, 100)\n)\n\n\n\n\ntribble(), short for “transposed tibble”, is designed for easy manual creation of tibbles. It allows for a column-wise specification of data which can be more readable and convenient for small datasets or examples.\n\nReadability: The layout of tribble() makes it easy to visually match values to their respective columns.\nConvenience: Ideal for creating small datasets for examples or tests.\n\n\n# Creating a tribble\nmy_tribble &lt;- tribble(\n  ~id, ~name,    ~score,\n  1,   \"Emma\",  90,\n  2,   \"Rony\",  80,\n  3,   \"Jostin\", 88,\n  4,   \"David\",  100,\n  5,   \"Alex\",    100\n)\n\n\n\n\nWhile data.frame is the base R structure for storing tabular data, tibble and tribble bring improvements that are particularly useful in data analysis:\n\nPrinting and Viewing: Tibbles provide a more user-friendly way to view data in the console.\nFactor conversion: By default, strings are not converted to factors in tibbles, avoiding unexpected behavior during data analysis.\nSubsetting behavior: Consistent output types make tibble subsetting more predictable.\nRow names: Tibbles do not use row names, which encourages cleaner, more explicit data manipulation.\n\nIn summary, tibble() and tribble() offer a modern, tidyverse-optimized approach to data frames, making data manipulation and exploration in R more intuitive and less prone to common data analysis pitfalls."
  },
  {
    "objectID": "content/02-data-cleaning.html#handling-missing-data",
    "href": "content/02-data-cleaning.html#handling-missing-data",
    "title": "Data Cleaning with the tidyverse",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\nReal-world datasets often come with missing values, which can significantly impact your analysis. Let’s explore strategies to deal with missing data. First, let’s create a dataframe and call it data using the tribble function:\n\n# Load sample data\ndata &lt;- tribble(\n  ~id, ~value, ~category,\n  1, NA, \"A\",\n  2, 5, \"B\",\n  3, 2, \"A\",\n  4, NA, \"B\",\n  5, 3, \"C\"\n)\n\n# Identify rows with missing values\ndata %&gt;% \n  filter(is.na(value))\n\n# A tibble: 2 × 3\n     id value category\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1     1    NA A       \n2     4    NA B       \n\n\nIn this case, the condition is is.na(value). The is.na() function checks for NA (missing) values in its argument. So, is.na(value) returns TRUE for each element in the value column that is missing (i.e., is NA) and FALSE for each element that is not missing.\nThe filter(is.na(value)) command, therefore, retains only those rows in the data where the value column has missing (NA) values. All other rows where the value column does not have missing values are excluded from the output. Sometimes (most of the time) we would like to return only the data without missing values, so we can negate the function is.na with !\n\n# Keeping only the rows with no missing values\ndata %&gt;% \n  filter(!is.na(value))\n\n# A tibble: 3 × 3\n     id value category\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1     2     5 B       \n2     3     2 A       \n3     5     3 C"
  },
  {
    "objectID": "content/02-data-cleaning.html#joining-datasets",
    "href": "content/02-data-cleaning.html#joining-datasets",
    "title": "Data Cleaning with the tidyverse",
    "section": "Joining Datasets",
    "text": "Joining Datasets\nOften, you’ll need to combine data from multiple sources. Here, we’ll use dplyr’s join functions to merge datasets.\nStudents and Departments Dataset\n\n# Students data\nstudents &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  stu_name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\"),\n  dept_id = c(2, 2, 3, 4)\n)\n\n# Departments data\ndepartments &lt;- tibble(\n  dept_id = c(1, 2, 3, 4),\n  dept_name = c(\"Math\", \"EDU\", \"Science\", \"ECON\")\n)\n\n\nleft_join\n\n# Include all students and their departments if available\nstu_dept &lt;- left_join(students, departments, by = \"dept_id\")\nstu_dept\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n\n\n\n\nright_join\n\n# Include all departments and any students in those departments\ndept_stu &lt;- right_join(students, departments, by = \"dept_id\")\ndept_stu\n\n# A tibble: 5 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n5     NA &lt;NA&gt;           1 Math     \n\n\n\n\nfull_join\n\n# Include all students and all departments, matching where possible\nall_stu_dept &lt;- full_join(students, departments, by = \"dept_id\")\nall_stu_dept\n\n# A tibble: 5 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n5     NA &lt;NA&gt;           1 Math     \n\n\n\n\ninner_join\n\n# Merge datasets to include only matching IDs\ninner_join(students, departments, by = \"dept_id\")\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON"
  },
  {
    "objectID": "content/02-data-cleaning.html#exploratory-data-analysis-eda",
    "href": "content/02-data-cleaning.html#exploratory-data-analysis-eda",
    "title": "Data Cleaning and Analysis with tidyverse:First Part",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nEDA is crucial for understanding the underlying patterns of your data. We’ll use ggplot2 for visualization.\n\nHistograms\nHistograms are great for visualizing the distribution of a numerical variable:\n\n# Using the `scores` dataset\nggplot(scores, aes(x = score)) +\n  geom_histogram(bins = 5, fill = \"grey\", color = \"black\") +\n  labs(title = \"Distribution of Scores\") +\n  theme_minimal()\n\n\n\n\n\n\nBoxplots\nBoxplots provide insights into the central tendency and spread of data, as well as outliers:\n\n# Using the `scores` dataset\nggplot(scores, aes(x = \"\", y = score)) +\n  geom_boxplot(fill = \"grey\", color = \"black\") +\n  labs(title = \"Score Spread\") +\n  theme_minimal()"
  },
  {
    "objectID": "content/01-basics.html#understanding-data-types-in-r",
    "href": "content/01-basics.html#understanding-data-types-in-r",
    "title": "Introduction to R: The Basics",
    "section": "Understanding Data Types in R",
    "text": "Understanding Data Types in R\nR supports various data types, each serving different purposes in data analysis. Familiarity with these data types is essential for effective data manipulation. Below are the primary data types you’ll encounter in R:\n\nNumeric\nNumeric data types are used to represent real numbers. They can be integers (without decimal points) or doubles (with decimal points), though R treats all numbers as floating-point values by default.\n\nmy_integer &lt;- 42  # An integer\nmy_double  &lt;- 42.5 # A double\n\n\n\nCharacter\nCharacter data types represent text. In R, text values are enclosed in quotes.\n\nmy_character &lt;- \"Hello, world! I love econometrics!\"\nmy_character\n\n[1] \"Hello, world! I love econometrics!\"\n\n\n\n\nLogical\nLogical (or boolean) data types represent TRUE or FALSE values. They are the result of conditions or logical operations.\n\nmy_logical &lt;- TRUE\nis_greater &lt;- (5 &gt; 2) # Evaluates to TRUE\n\nmy_logical\n\n[1] TRUE\n\nis_greater\n\n[1] TRUE\n\n\n\n\nFactor\nFactors are used to represent categorical data. They are especially useful for representing groups or levels (e.g., “Low”, “Medium”, “High”).\n\nmy_factor &lt;- factor(c(\"Low\", \"Medium\", \"High\", \"Low\", \"Medium\"))\n\nmy_factor\n\n[1] Low    Medium High   Low    Medium\nLevels: High Low Medium\n\n\n\n\nDate and POSIXct\nDate and POSIXct represent dates and date-times, respectively. They are crucial for time series analysis or any analysis that involves dates.\n\nmy_date     &lt;- as.Date(\"2024-01-01\")\nmy_datetime &lt;- as.POSIXct(\"2024-01-01 12:00:00\")\n\nmy_date\n\n[1] \"2024-01-01\"\n\nmy_datetime\n\n[1] \"2024-01-01 12:00:00 EST\"\n\n\n\n\nVectors\nVectors are basic data structures in R that contain elements of the same type. Use the c() function to create a vector:\n\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nmy_vector\n\n[1] 1 2 3 4 5\n\n\n\n\nList\nLists in R can contain elements of different types, including numbers, strings, vectors, and even other lists.\n\nmy_list &lt;- list(\n  name   = \"Eric Taylor\", \n  scores = c(90, 85, 88), \n  passed = TRUE\n)\n\nmy_list\n\n$name\n[1] \"Eric Taylor\"\n\n$scores\n[1] 90 85 88\n\n$passed\n[1] TRUE\n\n\nEach type has its specific purpose and a set of functions that operate on it, making it essential to choose the right type for your data analysis tasks.\n\n\nData Frame and Tibble\nA data frame is a table-like structure that can hold columns of different data types. A tibble is a modern take on the data frame, part of the tidyverse, designed to be more user-friendly. We will discuss more about this is the data cleaning section.\n\nmy_data_frame &lt;- data.frame(\n  id = 1:3,\n  name = c(\"Emma\", \"Rony\", \"Jostin\"),\n  score = c(90, 85, 88)\n)\n\nmy_tibble &lt;- tibble(\n  id = 1:3,\n  name = c(\"Emma\", \"Rony\", \"Jostin\"),\n  score = c(90, 85, 88)\n)\n\n\n\nBasic R Operations\nNow, let’s look at the basic operations. R can be used as a simple calculator. Try typing 2 + 2 in the console. You can assign values to variables using &lt;-.\n\nx &lt;- 2 + 2\nx\n\n[1] 4"
  },
  {
    "objectID": "content/01-basics.html#getting-help",
    "href": "content/01-basics.html#getting-help",
    "title": "Introduction to R: The Basics",
    "section": "Getting Help",
    "text": "Getting Help\nIf you don’t understand a function, you can use the question mark and the function you would like to know more about, like this:\n\n?mutate()"
  },
  {
    "objectID": "content/03-data-cleaning-part-ii.html",
    "href": "content/03-data-cleaning-part-ii.html",
    "title": "Data Cleaning and Analysis with tidyverse: Second Part",
    "section": "",
    "text": "In this tutorial, we delve into advanced data cleaning and analysis techniques focusing on student and department datasets. We will also demonstrate how to create custom functions in R to automate repetitive tasks in data analysis.\n\n\nWe will start by merging datasets using dplyr’s join functions to combine student information with department details.\n\n\n\n# Students data\nstudents &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  stu_name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\"),\n  dept_id = c(2, 2, 3, 4)\n)\n\n# Departments data\ndepartments &lt;- tibble(\n  dept_id = c(1, 2, 3, 4),\n  dept_name = c(\"Math\", \"EDU\", \"Science\", \"ECON\")\n)\n\n\n\n\n\n# Include all students and their departments if available\nstu_dept &lt;- left_join(students, departments, by = \"dept_id\")\nstu_dept\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n\n\n\n\n\n\n# Include all departments and any students in those departments\ndept_stu &lt;- right_join(students, departments, by = \"dept_id\")\ndept_stu\n\n# A tibble: 5 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n5     NA &lt;NA&gt;           1 Math     \n\n\n\n\n\n\n# Include all students and all departments, matching where possible\nall_stu_dept &lt;- full_join(students, departments, by = \"dept_id\")\nall_stu_dept\n\n# A tibble: 5 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n5     NA &lt;NA&gt;           1 Math     \n\n\n\n\n\n\nCreating custom functions can significantly enhance efficiency in data analysis. It might not be the case, but if you want to have a function that estimates the mean, sd, and std value in a column we can do the following. Let’s called it add_stats_columns. This function is designed to enhance a dataset by adding statistical analysis columns related to a specific numeric column within the dataset. It calculates the mean, standard deviation, and creates a standardized version of the selected column. Below is an explanation of the function and a breakdown of each line within it:\n\n\n\nadd_stats_columns &lt;- function(data, column_name) {\n  mean_val &lt;- mean(data[[column_name]], na.rm = TRUE)\n  sd_val   &lt;- sd(data[[column_name]], na.rm = TRUE)\n  \n  data[[paste0(column_name, \"_mean\")]] &lt;- mean_val\n  data[[paste0(column_name, \"_sd\")]]   &lt;- sd_val\n  data[[paste0(column_name, \"_standardized\")]] &lt;- (data[[column_name]] - mean_val) / sd_val\n  \n  return(data)\n}\n\n\n\n\nadd_stats_columns &lt;- function(data, column_name) { ... }: This line defines the function add_stats_columns that takes two arguments: data, a dataset (in the form of a data frame or tibble), and column_name, a string representing the name of the column to be analyzed.\nmean_val &lt;- mean(data[[column_name]], na.rm = TRUE): This line calculates the mean of the specified column, excluding any NA (missing) values with na.rm = TRUE, and stores it in mean_val.\nsd_val &lt;- sd(data[[column_name]], na.rm = TRUE): Similarly, this line calculates the standard deviation of the specified column, excluding NA values, and stores it in sd_val.\ndata[[paste0(column_name, \"_mean\")]] &lt;- mean_val: This line creates a new column in the dataset named after the original column with _mean appended (e.g., if column_name is \"scores\", the new column name will be \"scores_mean\"), and assigns the calculated mean value to this new column for all rows.\ndata[[paste0(column_name, \"_sd\")]] &lt;- sd_val: This line adds another new column to the dataset for the standard deviation, following the same naming convention as for the mean (e.g., \"scores_sd\"), and fills it with the calculated standard deviation value.\ndata[[paste0(column_name, \"_standardized\")]] &lt;- (data[[column_name]] - mean_val) / sd_val: This line calculates the standardized value for each row in the specified column by subtracting the mean and dividing by the standard deviation. It then stores these values in a new column named with _standardized appended to the original column name (e.g., \"scores_standardized\"). Standardizing a dataset in this way adjusts the values to have a mean of 0 and a standard deviation of 1, which is useful for certain types of analysis and modeling.\nreturn(data): Finally, the function returns the modified dataset with the new statistical columns added. In fact, you can just write data, do not need to use the return function but let’s keep it.\n\n\n\n\n\nAssuming students is a dataset with a numeric column named \"math_scores\", you can use the function to add statistical analysis columns related to \"math_scores\" as follows:\n\n# Example usage with a hypothetical numeric column in students dataset\n# Let's merge a math_scores data first.\nscores &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  math_scores = c(80, 95, 93, 90)\n)\n\n# Merge the scores with the students data using stu_id \nstu_scores &lt;- right_join(students, scores, by = \"stu_id\")\nstu_scores\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id math_scores\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1      1 Emma           2          80\n2      2 Rony           2          95\n3      3 Jostin         3          93\n4      4 David          4          90\n\n# Now, let's apply the function add_stats_columns\nstu_scores_with_stats &lt;- add_stats_columns(stu_scores, \"math_scores\")\nstu_scores_with_stats\n\n# A tibble: 4 × 7\n  stu_id stu_name dept_id math_scores math_scores_mean math_scores_sd\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1      1 Emma           2          80             89.5           6.66\n2      2 Rony           2          95             89.5           6.66\n3      3 Jostin         3          93             89.5           6.66\n4      4 David          4          90             89.5           6.66\n# ℹ 1 more variable: math_scores_standardized &lt;dbl&gt;\n\n\n\n\n\nUsing dplyr and purrr to apply functions to each group separately.\n\n# Group by department and apply stats function\nstudents_grouped &lt;- stu_scores %&gt;%\n  group_by(dept_id) %&gt;%\n  group_modify(~ add_stats_columns(.x, \"math_scores\")) %&gt;%\n  ungroup()\n\nstudents_grouped\n\n# A tibble: 4 × 7\n  dept_id stu_id stu_name math_scores math_scores_mean math_scores_sd\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1       2      1 Emma              80             87.5           10.6\n2       2      2 Rony              95             87.5           10.6\n3       3      3 Jostin            93             93             NA  \n4       4      4 David             90             90             NA  \n# ℹ 1 more variable: math_scores_standardized &lt;dbl&gt;\n\n\ngroup_modify() applies a function to each group of a grouped dataframe, where .x is the sliced dataframe for each group. This way, the add_stats_columns function is applied correctly to each department group within your stu_scores dataset.\nThis corrected approach ensures that your custom function add_stats_columns is applied to the math_scores column for each group defined by dept_id, achieving the intended goal of adding statistical columns based on department groups."
  },
  {
    "objectID": "content/03-data-cleaning-part-ii.html#merging-datasets",
    "href": "content/03-data-cleaning-part-ii.html#merging-datasets",
    "title": "Data Cleaning and Analysis with tidyverse: Second Part",
    "section": "",
    "text": "We will start by merging datasets using dplyr’s join functions to combine student information with department details.\n\n\n\n# Students data\nstudents &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  stu_name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\"),\n  dept_id = c(2, 2, 3, 4)\n)\n\n# Departments data\ndepartments &lt;- tibble(\n  dept_id = c(1, 2, 3, 4),\n  dept_name = c(\"Math\", \"EDU\", \"Science\", \"ECON\")\n)\n\n\n\n\n\n# Include all students and their departments if available\nstu_dept &lt;- left_join(students, departments, by = \"dept_id\")\nstu_dept\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n\n\n\n\n\n\n# Include all departments and any students in those departments\ndept_stu &lt;- right_join(students, departments, by = \"dept_id\")\ndept_stu\n\n# A tibble: 5 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n5     NA &lt;NA&gt;           1 Math     \n\n\n\n\n\n\n# Include all students and all departments, matching where possible\nall_stu_dept &lt;- full_join(students, departments, by = \"dept_id\")\nall_stu_dept\n\n# A tibble: 5 × 4\n  stu_id stu_name dept_id dept_name\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1      1 Emma           2 EDU      \n2      2 Rony           2 EDU      \n3      3 Jostin         3 Science  \n4      4 David          4 ECON     \n5     NA &lt;NA&gt;           1 Math"
  },
  {
    "objectID": "content/03-data-cleaning-part-ii.html#creating-functions-for-data-analysis",
    "href": "content/03-data-cleaning-part-ii.html#creating-functions-for-data-analysis",
    "title": "Data Cleaning and Analysis with tidyverse: Second Part",
    "section": "",
    "text": "Creating custom functions can significantly enhance efficiency in data analysis. It might not be the case, but if you want to have a function that estimates the mean, sd, and std value in a column we can do the following. Let’s called it add_stats_columns. This function is designed to enhance a dataset by adding statistical analysis columns related to a specific numeric column within the dataset. It calculates the mean, standard deviation, and creates a standardized version of the selected column. Below is an explanation of the function and a breakdown of each line within it:\n\n\n\nadd_stats_columns &lt;- function(data, column_name) {\n  mean_val &lt;- mean(data[[column_name]], na.rm = TRUE)\n  sd_val   &lt;- sd(data[[column_name]], na.rm = TRUE)\n  \n  data[[paste0(column_name, \"_mean\")]] &lt;- mean_val\n  data[[paste0(column_name, \"_sd\")]]   &lt;- sd_val\n  data[[paste0(column_name, \"_standardized\")]] &lt;- (data[[column_name]] - mean_val) / sd_val\n  \n  return(data)\n}\n\n\n\n\nadd_stats_columns &lt;- function(data, column_name) { ... }: This line defines the function add_stats_columns that takes two arguments: data, a dataset (in the form of a data frame or tibble), and column_name, a string representing the name of the column to be analyzed.\nmean_val &lt;- mean(data[[column_name]], na.rm = TRUE): This line calculates the mean of the specified column, excluding any NA (missing) values with na.rm = TRUE, and stores it in mean_val.\nsd_val &lt;- sd(data[[column_name]], na.rm = TRUE): Similarly, this line calculates the standard deviation of the specified column, excluding NA values, and stores it in sd_val.\ndata[[paste0(column_name, \"_mean\")]] &lt;- mean_val: This line creates a new column in the dataset named after the original column with _mean appended (e.g., if column_name is \"scores\", the new column name will be \"scores_mean\"), and assigns the calculated mean value to this new column for all rows.\ndata[[paste0(column_name, \"_sd\")]] &lt;- sd_val: This line adds another new column to the dataset for the standard deviation, following the same naming convention as for the mean (e.g., \"scores_sd\"), and fills it with the calculated standard deviation value.\ndata[[paste0(column_name, \"_standardized\")]] &lt;- (data[[column_name]] - mean_val) / sd_val: This line calculates the standardized value for each row in the specified column by subtracting the mean and dividing by the standard deviation. It then stores these values in a new column named with _standardized appended to the original column name (e.g., \"scores_standardized\"). Standardizing a dataset in this way adjusts the values to have a mean of 0 and a standard deviation of 1, which is useful for certain types of analysis and modeling.\nreturn(data): Finally, the function returns the modified dataset with the new statistical columns added. In fact, you can just write data, do not need to use the return function but let’s keep it.\n\n\n\n\n\nAssuming students is a dataset with a numeric column named \"math_scores\", you can use the function to add statistical analysis columns related to \"math_scores\" as follows:\n\n# Example usage with a hypothetical numeric column in students dataset\n# Let's merge a math_scores data first.\nscores &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  math_scores = c(80, 95, 93, 90)\n)\n\n# Merge the scores with the students data using stu_id \nstu_scores &lt;- right_join(students, scores, by = \"stu_id\")\nstu_scores\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id math_scores\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1      1 Emma           2          80\n2      2 Rony           2          95\n3      3 Jostin         3          93\n4      4 David          4          90\n\n# Now, let's apply the function add_stats_columns\nstu_scores_with_stats &lt;- add_stats_columns(stu_scores, \"math_scores\")\nstu_scores_with_stats\n\n# A tibble: 4 × 7\n  stu_id stu_name dept_id math_scores math_scores_mean math_scores_sd\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1      1 Emma           2          80             89.5           6.66\n2      2 Rony           2          95             89.5           6.66\n3      3 Jostin         3          93             89.5           6.66\n4      4 David          4          90             89.5           6.66\n# ℹ 1 more variable: math_scores_standardized &lt;dbl&gt;\n\n\n\n\n\nUsing dplyr and purrr to apply functions to each group separately.\n\n# Group by department and apply stats function\nstudents_grouped &lt;- stu_scores %&gt;%\n  group_by(dept_id) %&gt;%\n  group_modify(~ add_stats_columns(.x, \"math_scores\")) %&gt;%\n  ungroup()\n\nstudents_grouped\n\n# A tibble: 4 × 7\n  dept_id stu_id stu_name math_scores math_scores_mean math_scores_sd\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1       2      1 Emma              80             87.5           10.6\n2       2      2 Rony              95             87.5           10.6\n3       3      3 Jostin            93             93             NA  \n4       4      4 David             90             90             NA  \n# ℹ 1 more variable: math_scores_standardized &lt;dbl&gt;\n\n\ngroup_modify() applies a function to each group of a grouped dataframe, where .x is the sliced dataframe for each group. This way, the add_stats_columns function is applied correctly to each department group within your stu_scores dataset.\nThis corrected approach ensures that your custom function add_stats_columns is applied to the math_scores column for each group defined by dept_id, achieving the intended goal of adding statistical columns based on department groups."
  },
  {
    "objectID": "content/04-regex.html",
    "href": "content/04-regex.html",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Regular expressions are a powerful tool for pattern matching, searching, and replacing text. R, through the stringr package from the tidyverse, provides a suite of functions that make working with regular expressions straightforward.\n\n\nA regular expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains the specified search pattern.\n\n\n\n.: Matches any single character.\n^: Matches the start of a string.\n$: Matches the end of a string.\n*: Matches zero or more occurrences of the preceding element.\n+: Matches one or more occurrences of the preceding element.\n?: Matches zero or one occurrence of the preceding element.\n\\\\d: Matches any digits.\n\\\\w: Matches any word character (alphanumeric or underscore).\n[...]: Matches any single character contained within the brackets.\n|: Logical OR operator.\n\n\n\n\n\nThe stringr package simplifies the use of regular expressions in R. Here are some common functions:\n\n\nChecks if strings match a pattern.\n\ntexts &lt;- c(\"apple\", \"banana\", \"pear\", \"orange\")\nstr_detect(texts, pattern = \"a\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n\n\nExtracts the first occurrence of a pattern.\n\nstr_extract(texts, pattern = \"\\\\b[a-z]*a\\\\b\")\n\n[1] NA       \"banana\" NA       NA      \n\n\n\n\n\nReplaces the first occurrence of a pattern.\n\nstr_replace(texts, pattern = \"a\", replacement = \"@\")\n\n[1] \"@pple\"  \"b@nana\" \"pe@r\"   \"or@nge\"\n\n\n\n\n\nSplits strings based on a pattern.\n\nstr_split(texts, pattern = \"a\")\n\n[[1]]\n[1] \"\"     \"pple\"\n\n[[2]]\n[1] \"b\" \"n\" \"n\" \"\" \n\n[[3]]\n[1] \"pe\" \"r\" \n\n[[4]]\n[1] \"or\"  \"nge\"\n\n\n\n\n\n\n\n\nUsing a more complex regex to find email addresses in a string.\n\nsample_text &lt;- \"Contact us at info@example.com or support@example.org\"\nemail_pattern &lt;- \"[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,}\"\nstr_extract_all(sample_text, pattern = email_pattern)\n\n[[1]]\n[1] \"info@example.com\"    \"support@example.org\"\n\n\n\n\n\nCheck if strings are valid phone numbers.\n\nphone_numbers &lt;- c(\"123-456-7890\", \"987 654 3210\", \"Invalid Number\")\nphone_pattern &lt;- \"^\\\\d{3}[- ]?\\\\d{3}[- ]?\\\\d{4}$\"\nstr_detect(phone_numbers, pattern = phone_pattern)\n\n[1]  TRUE  TRUE FALSE\n\n\n\n\n\n\nRegular expressions are a versatile and powerful tool for text processing. The stringr package from the tidyverse makes regex operations in R both accessible and efficient. By mastering regular expressions, you can perform complex text manipulations and data cleaning tasks with ease."
  },
  {
    "objectID": "content/04-regex.html#basic-concepts",
    "href": "content/04-regex.html#basic-concepts",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "A regular expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains the specified search pattern.\n\n\n\n.: Matches any single character.\n^: Matches the start of a string.\n$: Matches the end of a string.\n*: Matches zero or more occurrences of the preceding element.\n+: Matches one or more occurrences of the preceding element.\n?: Matches zero or one occurrence of the preceding element.\n\\\\d: Matches any digits.\n\\\\w: Matches any word character (alphanumeric or underscore).\n[...]: Matches any single character contained within the brackets.\n|: Logical OR operator."
  },
  {
    "objectID": "content/04-regex.html#using-stringr-for-regex-operations",
    "href": "content/04-regex.html#using-stringr-for-regex-operations",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "The stringr package simplifies the use of regular expressions in R. Here are some common functions:\n\n\nChecks if strings match a pattern.\n\ntexts &lt;- c(\"apple\", \"banana\", \"pear\", \"orange\")\nstr_detect(texts, pattern = \"a\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n\n\nExtracts the first occurrence of a pattern.\n\nstr_extract(texts, pattern = \"\\\\b[a-z]*a\\\\b\")\n\n[1] NA       \"banana\" NA       NA      \n\n\n\n\n\nReplaces the first occurrence of a pattern.\n\nstr_replace(texts, pattern = \"a\", replacement = \"@\")\n\n[1] \"@pple\"  \"b@nana\" \"pe@r\"   \"or@nge\"\n\n\n\n\n\nSplits strings based on a pattern.\n\nstr_split(texts, pattern = \"a\")\n\n[[1]]\n[1] \"\"     \"pple\"\n\n[[2]]\n[1] \"b\" \"n\" \"n\" \"\" \n\n[[3]]\n[1] \"pe\" \"r\" \n\n[[4]]\n[1] \"or\"  \"nge\""
  },
  {
    "objectID": "content/04-regex.html#advanced-examples",
    "href": "content/04-regex.html#advanced-examples",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Using a more complex regex to find email addresses in a string.\n\nsample_text &lt;- \"Contact us at info@example.com or support@example.org\"\nemail_pattern &lt;- \"[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,}\"\nstr_extract_all(sample_text, pattern = email_pattern)\n\n[[1]]\n[1] \"info@example.com\"    \"support@example.org\"\n\n\n\n\n\nCheck if strings are valid phone numbers.\n\nphone_numbers &lt;- c(\"123-456-7890\", \"987 654 3210\", \"Invalid Number\")\nphone_pattern &lt;- \"^\\\\d{3}[- ]?\\\\d{3}[- ]?\\\\d{4}$\"\nstr_detect(phone_numbers, pattern = phone_pattern)\n\n[1]  TRUE  TRUE FALSE"
  },
  {
    "objectID": "content/04-regex.html#conclusion",
    "href": "content/04-regex.html#conclusion",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Regular expressions are a versatile and powerful tool for text processing. The stringr package from the tidyverse makes regex operations in R both accessible and efficient. By mastering regular expressions, you can perform complex text manipulations and data cleaning tasks with ease."
  },
  {
    "objectID": "content/05-data-viz.html",
    "href": "content/05-data-viz.html",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "Visualizing data is crucial in understanding underlying patterns and communicating results effectively. This tutorial will guide you through creating various types of visualizations using ggplot2 in R, focusing on a dataset of student scores (a fake dataset btw).\n\n\nFirst, we’ll load the dataset from a CSV file, and load the tidyverse package.\n\n# Load the package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the dataset\nscores_data &lt;- read_csv(\"../files/data/fake_scores.csv\")\n\nRows: 96 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): course, student, concentration\ndbl (2): studentid, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis dataset contains students (fake) information, you can use the glimpse function to look at the variables in the dataset. Table 1 shows a representation of the data we loaded as a table.\n\n\n\n\nTable 1: Data from the fake_scores.csv file as a table.\n\n\ncourse\nstudent\nstudentid\nscore\nconcentration\n\n\n\n\nEDU 001\nJostin\n1\n10\nEPPE\n\n\nEDU 001\nRony\n2\n6\nEPPE\n\n\nEDU 001\nJacob\n3\n87\nCIS\n\n\nEDU 001\nHwa\n4\n75\nCIS\n\n\nEDU 001\nEmma\n5\n19\nCIS\n\n\nEDU 001\nBen\n6\n9\nCIS\n\n\n\n\n\n\n\nglimpse(scores_data)\n\nRows: 96\nColumns: 5\n$ course        &lt;chr&gt; \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"…\n$ student       &lt;chr&gt; \"Jostin\", \"Rony\", \"Jacob\", \"Hwa\", \"Emma\", \"Ben\", \"Maddie…\n$ studentid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ score         &lt;dbl&gt; 10, 6, 87, 75, 19, 9, 40, 72, 97, 45, 33, 24, 24, 74, 69…\n$ concentration &lt;chr&gt; \"EPPE\", \"EPPE\", \"CIS\", \"CIS\", \"CIS\", \"CIS\", \"HDLT\", \"CIS…\n\n\n\n\n\nggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics. ggplot2 uses a grammar of graphics, where you define the data, aesthetics, and geometries.\n\n\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\n\nHistograms are great for visualizing the distribution of scores for a single subject. Let’s visualize the distribution of all scores in the dataset.\n\nscores_data %&gt;% \n  ggplot( \n    aes(x = score)\n  ) +\n  geom_histogram(\n    fill = \"grey\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribution of All Scores\",\n    x = \"All Scores\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nscores_data: The dataset being used, assumed to contain a column named score which holds the numeric values that we want to visualize.\n%&gt;%: The pipe operator, used here to pass scores_data as the first argument to the following ggplot() function.\nggplot(aes(x = score)): Initializes a ggplot object specifying the aesthetic mappings. Here, aes(x = score) indicates that the score column from scores_data should be used as the x-axis values in the histogram.\ngeom_histogram(): This adds a histogram layer to the plot.\nfill = \"grey\": Sets the fill color of the bars in the histogram to grey.\ncolor = \"black\": Sets the color of the border of the bars to black.\nlabs(): Used to modify the labels on the plot, including the title of the plot and the x and y axes. Here, it sets the title of the plot to “Distribution of All Scores”, labels the x-axis as “All Scores”, and the y-axis as “Count”, which represents the number of observations within each bin of scores.\ntheme_minimal(): Applies a minimalistic theme to the plot, which reduces the background clutter and focuses attention on the data itself.\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: The use of the + operator instead of the pipe operator (%&gt;%) in ggplot2 syntax is rooted in the design and philosophy of the ggplot2 package itself, which is based on the Grammar of Graphics.\n\nLayered Approach: ggplot2 is built on the concept of layering components of a plot on top of each other. The + operator is used to add or layer these components, such as axes, plot types (geoms), scales, and themes, to build up a plot step by step. This approach is akin to constructing a sentence in a language, where each layer adds more context or detail, aligning with the Grammar of Graphics philosophy.\n\n\n\n\n\n\nLet’s start with a scatter plot comparing scores across two subjects, assuming our dataset has Math and Science scores. However, see that your dataset currently is in long format. So, we need to change it to wide format. Look at the following code chunk:\n\nscores_data_wide &lt;- scores_data %&gt;% \n  filter(\n    course %in% c(\"EDU 001\", \"EDU 302\")\n  ) %&gt;% \n  pivot_wider(\n    names_from = course, \n    values_from = score\n  )\n\nscores_data_wide\n\n# A tibble: 24 × 5\n   student studentid concentration `EDU 001` `EDU 302`\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 Jostin          1 EPPE                 10         0\n 2 Rony            2 EPPE                  6        75\n 3 Jacob           3 CIS                  87         6\n 4 Hwa             4 CIS                  75        75\n 5 Emma            5 CIS                  19        48\n 6 Ben             6 CIS                   9         1\n 7 Maddie          7 HDLT                 40        89\n 8 Alex            8 CIS                  72        52\n 9 Krista          9 CIS                  97        61\n10 Max            10 HDLT                 45        15\n# ℹ 14 more rows\n\n\nThis will give a dataset with 24 observations and the two subject (EDU 001 and EDU 302) as columns.The pivot_wider function creates new columns for each course, with scores filled in accordingly.\n\nfilter(course %in% c(\"EDU 001\", \"EDU 302\")): Narrows down the dataset to only include scores from the specified courses.\npivot_wider(names_from = course, values_from = score): Transforms the dataset so each course becomes its own column, populated with corresponding scores.\n\nNow, let’s plot the scores in the two courses.\n\nscores_data_wide %&gt;% \n  ggplot(\n    aes(x = `EDU 001`, y = `EDU 302`)\n  ) +\n  geom_point() +\n  labs(\n    title = \"EDU 001 vs. EDU 302\",\n    x = \"EDU 001 Scores\",\n    y = \"EDU 302 Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nVisualizing data based on groups or categories is often insightful.\n\n\nUsing our dataset in long format, where each row represents a score in a specific course\n\nscores_data %&gt;% \n  ggplot(\n    aes(\n      x = course, \n      y = score, \n      fill = course\n    )\n  ) +\n  geom_boxplot() +\n  labs(\n    title = \"Scores by course\",\n    x = \"course\",\n    y = \"Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nA bar plot to visualize the average score per subject.\n\nscores_data %&gt;%\n  group_by(course) %&gt;%\n  summarise(\n    avg_score = mean(score)\n  ) %&gt;%\n  ggplot(\n    aes(\n      x = course, \n      y = avg_score, \n      fill = course\n    )\n  ) +\n  geom_col(color = \"black\") +\n  labs(\n    title = \"Average Scores by Course\",\n    x = \"Course\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis tutorial introduced basic to intermediate data visualization techniques using ggplot2 in R. By leveraging ggplot2’s comprehensive features, you can create informative and appealing visual representations of your data to aid in analysis and communication."
  },
  {
    "objectID": "content/05-data-viz.html#loading-the-dataset",
    "href": "content/05-data-viz.html#loading-the-dataset",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "First, we’ll load the dataset from a CSV file, and load the tidyverse package.\n\n# Load the package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the dataset\nscores_data &lt;- read_csv(\"../files/data/fake_scores.csv\")\n\nRows: 96 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): course, student, concentration\ndbl (2): studentid, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis dataset contains students (fake) information, you can use the glimpse function to look at the variables in the dataset. Table 1 shows a representation of the data we loaded as a table.\n\n\n\n\nTable 1: Data from the fake_scores.csv file as a table.\n\n\ncourse\nstudent\nstudentid\nscore\nconcentration\n\n\n\n\nEDU 001\nJostin\n1\n10\nEPPE\n\n\nEDU 001\nRony\n2\n6\nEPPE\n\n\nEDU 001\nJacob\n3\n87\nCIS\n\n\nEDU 001\nHwa\n4\n75\nCIS\n\n\nEDU 001\nEmma\n5\n19\nCIS\n\n\nEDU 001\nBen\n6\n9\nCIS\n\n\n\n\n\n\n\nglimpse(scores_data)\n\nRows: 96\nColumns: 5\n$ course        &lt;chr&gt; \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"…\n$ student       &lt;chr&gt; \"Jostin\", \"Rony\", \"Jacob\", \"Hwa\", \"Emma\", \"Ben\", \"Maddie…\n$ studentid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ score         &lt;dbl&gt; 10, 6, 87, 75, 19, 9, 40, 72, 97, 45, 33, 24, 24, 74, 69…\n$ concentration &lt;chr&gt; \"EPPE\", \"EPPE\", \"CIS\", \"CIS\", \"CIS\", \"CIS\", \"HDLT\", \"CIS…"
  },
  {
    "objectID": "content/05-data-viz.html#understanding-ggplot2",
    "href": "content/05-data-viz.html#understanding-ggplot2",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "ggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics. ggplot2 uses a grammar of graphics, where you define the data, aesthetics, and geometries.\n\n\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\n\nHistograms are great for visualizing the distribution of scores for a single subject. Let’s visualize the distribution of all scores in the dataset.\n\nscores_data %&gt;% \n  ggplot( \n    aes(x = score)\n  ) +\n  geom_histogram(\n    fill = \"grey\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribution of All Scores\",\n    x = \"All Scores\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nscores_data: The dataset being used, assumed to contain a column named score which holds the numeric values that we want to visualize.\n%&gt;%: The pipe operator, used here to pass scores_data as the first argument to the following ggplot() function.\nggplot(aes(x = score)): Initializes a ggplot object specifying the aesthetic mappings. Here, aes(x = score) indicates that the score column from scores_data should be used as the x-axis values in the histogram.\ngeom_histogram(): This adds a histogram layer to the plot.\nfill = \"grey\": Sets the fill color of the bars in the histogram to grey.\ncolor = \"black\": Sets the color of the border of the bars to black.\nlabs(): Used to modify the labels on the plot, including the title of the plot and the x and y axes. Here, it sets the title of the plot to “Distribution of All Scores”, labels the x-axis as “All Scores”, and the y-axis as “Count”, which represents the number of observations within each bin of scores.\ntheme_minimal(): Applies a minimalistic theme to the plot, which reduces the background clutter and focuses attention on the data itself.\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: The use of the + operator instead of the pipe operator (%&gt;%) in ggplot2 syntax is rooted in the design and philosophy of the ggplot2 package itself, which is based on the Grammar of Graphics.\n\nLayered Approach: ggplot2 is built on the concept of layering components of a plot on top of each other. The + operator is used to add or layer these components, such as axes, plot types (geoms), scales, and themes, to build up a plot step by step. This approach is akin to constructing a sentence in a language, where each layer adds more context or detail, aligning with the Grammar of Graphics philosophy.\n\n\n\n\n\n\nLet’s start with a scatter plot comparing scores across two subjects, assuming our dataset has Math and Science scores. However, see that your dataset currently is in long format. So, we need to change it to wide format. Look at the following code chunk:\n\nscores_data_wide &lt;- scores_data %&gt;% \n  filter(\n    course %in% c(\"EDU 001\", \"EDU 302\")\n  ) %&gt;% \n  pivot_wider(\n    names_from = course, \n    values_from = score\n  )\n\nscores_data_wide\n\n# A tibble: 24 × 5\n   student studentid concentration `EDU 001` `EDU 302`\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 Jostin          1 EPPE                 10         0\n 2 Rony            2 EPPE                  6        75\n 3 Jacob           3 CIS                  87         6\n 4 Hwa             4 CIS                  75        75\n 5 Emma            5 CIS                  19        48\n 6 Ben             6 CIS                   9         1\n 7 Maddie          7 HDLT                 40        89\n 8 Alex            8 CIS                  72        52\n 9 Krista          9 CIS                  97        61\n10 Max            10 HDLT                 45        15\n# ℹ 14 more rows\n\n\nThis will give a dataset with 24 observations and the two subject (EDU 001 and EDU 302) as columns.The pivot_wider function creates new columns for each course, with scores filled in accordingly.\n\nfilter(course %in% c(\"EDU 001\", \"EDU 302\")): Narrows down the dataset to only include scores from the specified courses.\npivot_wider(names_from = course, values_from = score): Transforms the dataset so each course becomes its own column, populated with corresponding scores.\n\nNow, let’s plot the scores in the two courses.\n\nscores_data_wide %&gt;% \n  ggplot(\n    aes(x = `EDU 001`, y = `EDU 302`)\n  ) +\n  geom_point() +\n  labs(\n    title = \"EDU 001 vs. EDU 302\",\n    x = \"EDU 001 Scores\",\n    y = \"EDU 302 Scores\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "content/05-data-viz.html#grouped-visualizations",
    "href": "content/05-data-viz.html#grouped-visualizations",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "Visualizing data based on groups or categories is often insightful.\n\n\nUsing our dataset in long format, where each row represents a score in a specific course\n\nscores_data %&gt;% \n  ggplot(\n    aes(\n      x = course, \n      y = score, \n      fill = course\n    )\n  ) +\n  geom_boxplot() +\n  labs(\n    title = \"Scores by course\",\n    x = \"course\",\n    y = \"Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nA bar plot to visualize the average score per subject.\n\nscores_data %&gt;%\n  group_by(course) %&gt;%\n  summarise(\n    avg_score = mean(score)\n  ) %&gt;%\n  ggplot(\n    aes(\n      x = course, \n      y = avg_score, \n      fill = course\n    )\n  ) +\n  geom_col(color = \"black\") +\n  labs(\n    title = \"Average Scores by Course\",\n    x = \"Course\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "content/05-data-viz.html#conclusion",
    "href": "content/05-data-viz.html#conclusion",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "This tutorial introduced basic to intermediate data visualization techniques using ggplot2 in R. By leveraging ggplot2’s comprehensive features, you can create informative and appealing visual representations of your data to aid in analysis and communication."
  },
  {
    "objectID": "content/01-basics.html#summarizing-data-with-summarize",
    "href": "content/01-basics.html#summarizing-data-with-summarize",
    "title": "Introduction to R: The Basics",
    "section": "Summarizing Data with summarize()",
    "text": "Summarizing Data with summarize()\nThe summarize() function in dplyr is used to create summary statistics for a dataset or subsets of a dataset. This function can be particularly powerful when combined with group_by(), which groups the data frame by one or more variables.\n\nBasic Usage of summarize()\nHere’s how you can use summarize() to calculate the average (mean) score of all students in my_data_frame:\n\naverage_score &lt;- my_data_frame %&gt;%\n  summarize(\n    mean_score = mean(score)\n  )\n\naverage_score\n\n  mean_score\n1   87.66667\n\n\nThis code calculates the mean of the score column and stores the result in a new data frame called average_score with a single column mean_score.\nNow, image that you have some observations with missing values for score. In that case, you would like to ignore those missing values when estimating the mean score. Therefore, instead of using mean(score) you can use the argument na.rm = TRUE, as follows: mean(score, na.rm = TRUE).\n\n\nGrouped Summaries\nTo calculate the average score by a categorical variable (e.g., by a hypothetical class column), you first group the data by that variable using group_by(), then apply summarize():\nFirst, let’s add a hypothetical class variable to our data frame to categorize students into two classes, “A” and “B”. We’ll use the mutate() function to accomplish this:\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    class = if_else(id %% 2 == 0, \"A\", \"B\")\n  )\n\nmy_data_frame\n\n  id   name score passed score_standardized grade class\n1  1   Emma    90   TRUE          0.9271726     B     B\n2  2   Rony    85   TRUE         -1.0596259     C     A\n3  3 Jostin    88   TRUE          0.1324532     B     B\n\n\nThis code adds a new column class to my_data_frame, where students with an even id are assigned to class “A” and students with an odd id are assigned to class “B”.\nNow that we have a class variable, we can calculate the average score for each class:\n\naverage_score_by_class &lt;- my_data_frame %&gt;%\n  group_by(class) %&gt;%\n  summarize(\n    mean_score = mean(score)\n  )\n\naverage_score_by_class\n\n# A tibble: 2 × 2\n  class mean_score\n  &lt;chr&gt;      &lt;dbl&gt;\n1 A             85\n2 B             89\n\n\nThis will calculate the mean score for each class separately.\n\n\nMultiple functions within a summarize.\nYou can also use summarize() to apply multiple summary functions at once. For example, to calculate the mean, median, and standard deviation of scores:\n\nsummary_statistics &lt;- my_data_frame %&gt;%\n  summarize(\n    mean_score = mean(score),\n    median_score = median(score),\n    sd_score = sd(score)\n  )\n\nsummary_statistics\n\n  mean_score median_score sd_score\n1   87.66667           88 2.516611\n\n\n\n\nUsing summarize() with mutate()\nWhile summarize() reduces your data to a single summary row, mutate() can be used alongside to add summary columns to the original data frame. For example, adding a column with the mean score to each row:\n\nmy_data_frame_with_mean &lt;- my_data_frame %&gt;%\n  mutate(mean_score = mean(score))\n\nmy_data_frame_with_mean\n\n  id   name score passed score_standardized grade class mean_score\n1  1   Emma    90   TRUE          0.9271726     B     B   87.66667\n2  2   Rony    85   TRUE         -1.0596259     C     A   87.66667\n3  3 Jostin    88   TRUE          0.1324532     B     B   87.66667"
  },
  {
    "objectID": "content/06-data-summ.html",
    "href": "content/06-data-summ.html",
    "title": "Building Summary Statistics Tables",
    "section": "",
    "text": "modelsummary and gtsummary are two excellent r packages to build summary statistics. However, their syntax might not be fully intuitive if you are comming from Stata. Here are a couple of examples using these two packages.\nFirst, let’s load the following packages and load our data:\n\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(modelsummary)\nlibrary(haven)\n\ncensus &lt;- read_dta(\"http://www.stata-press.com/data/r9/census.dta\") %&gt;%\n  # Create dummy treatment\n  mutate(\n    rand = runif(n()),\n    treatment = as.numeric(rand &gt; 0.5)\n  )\n\nI’m using the census stata dta file for those who are familiar with this Stata dataset."
  },
  {
    "objectID": "content/06-data-summ.html#model-summary",
    "href": "content/06-data-summ.html#model-summary",
    "title": "Building Summary Statistics Tables",
    "section": "Model Summary",
    "text": "Model Summary\nWhen it comes to model summary, we have two approaches: (1) a rapid data summary, and (2) a more elaborated one. For the former, we use the datasummary_skim() function as follows:\n\ndatasummary_skim(census)\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\n\nCensus region\n4\n0\n2.7\n1.1\n1.0\n3.0\n4.0\n\n\n\npop\n50\n0\n4518149.4\n4715037.8\n401851.0\n3066433.0\n23667902.0\n\n\n\npoplt5\n50\n0\n326277.8\n331585.1\n35998.0\n227467.5\n1708400.0\n\n\n\npop5_17\n50\n0\n945951.6\n959372.8\n91796.0\n629654.0\n4680558.0\n\n\n\npop18p\n50\n0\n3245920.1\n3430531.3\n271106.0\n2175130.0\n17278944.0\n\n\n\npop65p\n50\n0\n509502.8\n538932.4\n11547.0\n370495.0\n2414250.0\n\n\n\npopurban\n50\n0\n3328253.2\n4090177.9\n172735.0\n2156905.0\n21607606.0\n\n\n\nmedage\n37\n0\n29.5\n1.7\n24.2\n29.8\n34.7\n\n\n\ndeath\n50\n0\n39474.3\n41742.3\n1604.0\n26176.5\n186428.0\n\n\n\nmarriage\n50\n0\n47701.4\n45130.4\n4437.0\n36279.0\n210864.0\n\n\n\ndivorce\n50\n0\n23679.4\n25094.0\n2142.0\n17112.5\n133541.0\n\n\n\nrand\n50\n0\n0.5\n0.3\n0.0\n0.6\n1.0\n\n\n\ntreatment\n2\n0\n0.6\n0.5\n0.0\n1.0\n1.0\n\n\n\n\n\n\n\n\nIf we want to select only a few variables, we could past a variables vector to the select function or create a new object with only the variables we need.\n\ncensus %&gt;%\n  select(pop, death, marriage, divorce) %&gt;%\n  datasummary_skim()\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\n\npop\n50\n0\n4518149.4\n4715037.8\n401851.0\n3066433.0\n23667902.0\n\n\n\ndeath\n50\n0\n39474.3\n41742.3\n1604.0\n26176.5\n186428.0\n\n\n\nmarriage\n50\n0\n47701.4\n45130.4\n4437.0\n36279.0\n210864.0\n\n\n\ndivorce\n50\n0\n23679.4\n25094.0\n2142.0\n17112.5\n133541.0\n\n\n\n\n\n\n\n\nIn addition, we can let the function knows if we would like to have only summary statistics for those variables that are either numeric or categorical, for example:\n\ndatasummary_skim(census, type = \"numeric\")\n\nIf we would like to have only the mean, sd, min, max instead of all the statistics that are presented using datasummary_skim we can use a 2-sided formula.\n\nbuild &lt;- pop + death + marriage + divorce ~ N + Mean + SD + Median + Min + Max \n\n## Without labels\n\ndatasummary(\n  build,\n  data = census\n) \n\n\n\n\n\nN\nMean\nSD\nMedian\nMin\nMax\n\n\n\n\npop\n50\n4518149.44\n4715037.75\n3066433.00\n401851.00\n23667902.00\n\n\ndeath\n50\n39474.26\n41742.35\n26176.50\n1604.00\n186428.00\n\n\nmarriage\n50\n47701.40\n45130.42\n36279.00\n4437.00\n210864.00\n\n\ndivorce\n50\n23679.44\n25094.01\n17112.50\n2142.00\n133541.00\n\n\n\n\n\n\n\nIn the case of variables labels, we will need to modify those variables names.\n\n## With labels\n\nbuild &lt;- `Population` + `Number of deaths` + `Number of marriages` + `Number of divorces` ~ N + Mean + SD + Median + Min + Max \n\ndatasummary(\n  build,\n  data = census %&gt;% \n    rename(`Population` = pop, `Number of deaths` = death, `Number of marriages` = marriage, `Number of divorces` = divorce)\n) \n\n\n\n\n\nN\nMean\nSD\nMedian\nMin\nMax\n\n\n\n\nPopulation\n50\n4518149.44\n4715037.75\n3066433.00\n401851.00\n23667902.00\n\n\nNumber of deaths\n50\n39474.26\n41742.35\n26176.50\n1604.00\n186428.00\n\n\nNumber of marriages\n50\n47701.40\n45130.42\n36279.00\n4437.00\n210864.00\n\n\nNumber of divorces\n50\n23679.44\n25094.01\n17112.50\n2142.00\n133541.00\n\n\n\n\n\n\n\nFinally, we can use the output argument to export our table to a several file formats.\n\nbuild &lt;- pop + death + marriage + divorce ~ N + Mean + SD + Median + Min + Max \n\ndatasummary(\n  build,\n  data = census,\n  output = \"latex\"\n) \n\nIn the case of latex, your output would like this and you can use the \\input command in your latex document to add your table to your reports or working papers:\n\n\\begin{table}\n  \\centering\n  \\begin{tabular}[t]{lrrrrrr}\n  \\toprule\n  & N & Mean & SD & Median & Min & Max\\\\\n  \\midrule\n  pop & 50 & \\num{4518149.44} & \\num{4715037.75} & \\num{3066433.00} & \\num{401851.00} & \\num{23667902.00}\\\\\n  death & 50 & \\num{39474.26} & \\num{41742.35} & \\num{26176.50} & \\num{1604.00} & \\num{186428.00}\\\\\n  marriage & 50 & \\num{47701.40} & \\num{45130.42} & \\num{36279.00} & \\num{4437.00} & \\num{210864.00}\\\\\n  divorce & 50 & \\num{23679.44} & \\num{25094.01} & \\num{17112.50} & \\num{2142.00} & \\num{133541.00}\\\\\n  \\bottomrule\n  \\end{tabular}\n\\end{table}\n\nCheck the official official vignette for more examples."
  },
  {
    "objectID": "content/06-data-summ.html#gt-summary",
    "href": "content/06-data-summ.html#gt-summary",
    "title": "Building Summary Statistics Tables",
    "section": "GT Summary",
    "text": "GT Summary\ngtsummary is another package that can be used for basic and complex summary statistics. Its syntax follows the gt family. For a basic summary statistics table, we can use the tbl_summary() function as follows:\n\nvars &lt;- c(\"pop\", \"death\", \"marriage\", \"divorce\")\n\ntab1 &lt;- census %&gt;% \n  select(all_of(vars)) %&gt;% \n  tbl_summary()\n\n\n\n\n\n\nBy treatment variable:\n\ntab2 &lt;- census %&gt;%\n  select(all_of(vars), treatment) %&gt;%\n  tbl_summary(by = treatment) %&gt;%\n  add_p()\n\n\n\n\n\n\nGiven that we would like to have a more econ-paper type of descriptive statistics, we can pass the columns we would like to have it in a vectorized way.\n\ncols &lt;- c(N = \"{N_nonmiss}\", Mean = \"{mean} ({sd})\", Median = \"{median}\", Min = \"{min}\", Max = \"{max}\")\ntab3 &lt;- cols %&gt;% \n  # we would go through each of these columns\n  imap(\n    ~ census %&gt;% \n      # and select the variables we need in our table\n      select(all_of(vars)) %&gt;% \n      tbl_summary(\n        statistic = all_continuous() ~ .x\n      ) %&gt;% \n      # We will modify the title of cols headers\n      modify_header(stat_0 ~ str_glue(\"{.y}\"), label ~ \"Variables\") \n  ) %&gt;% \n  # and merge every single of the columns into one single table\n  tbl_merge() %&gt;% \n  # remove spanning headers and footnote\n  modify_spanning_header(everything() ~ NA) %&gt;%\n  modify_footnote(everything() ~ NA) \n\n\n\n\n\n\nAnd, finally, we can use the as_kable_extra function to export our table to latex. The full example is here below:\n\ntab3 %&gt;%\n  as_kable_extra(\n    format = \"latex\", \n    booktabs = TRUE, \n    linesep = \"\"\n  )\n\n\n\n\nThat gives you the following latex code:\n\n\\begin{tabular}{lccccc}\n  \\toprule\n  Variables & N & Mean & Median & Min & Max\\\\\n  \\midrule\n  Population & 50 & 4,518,149 (4,715,038) & 3,066,433 & 401,851 & 23,667,902\\\\\n  Number of deaths & 50 & 39,474 (41,742) & 26,176 & 1,604 & 186,428\\\\\n  Number of marriages & 50 & 47,701 (45,130) & 36,279 & 4,437 & 210,864\\\\\n  Number of divorces & 50 & 23,679 (25,094) & 17,112 & 2,142 & 133,541\\\\\n  \\bottomrule\n\\end{tabular}\n\nCheck the official official vignette for more examples."
  },
  {
    "objectID": "content/06-data-summ.html#pdf-example",
    "href": "content/06-data-summ.html#pdf-example",
    "title": "Building Summary Statistics Tables",
    "section": "PDF Example",
    "text": "PDF Example\nA compiled PDF example of some of the tables that were created here can be found here"
  },
  {
    "objectID": "content/06-data-summ.html#introduction",
    "href": "content/06-data-summ.html#introduction",
    "title": "Building Summary Statistics Tables",
    "section": "",
    "text": "modelsummary and gtsummary are two excellent r packages to build summary statistics. However, their syntax might not be fully intuitive if you are comming from Stata. Here are a couple of examples using these two packages.\nFirst, let’s load the following packages and load our data:\n\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(modelsummary)\nlibrary(haven)\n\ncensus &lt;- read_dta(\"http://www.stata-press.com/data/r9/census.dta\") %&gt;%\n  # Create dummy treatment\n  mutate(\n    rand = runif(n()),\n    treatment = as.numeric(rand &gt; 0.5)\n  )\n\nI’m using the census stata dta file for those who are familiar with this Stata dataset."
  },
  {
    "objectID": "content/01-basics.html#introduction",
    "href": "content/01-basics.html#introduction",
    "title": "Introduction to R: The Basics",
    "section": "",
    "text": "Welcome to this introductory tutorial on R! R is a powerful language and environment for statistical computing and graphics. It offers a wide variety of statistical and graphical techniques and is highly extensible. One of the key features of R is its package ecosystem, the most notable of which is the tidyverse, a collection of packages designed for data science.\nThis tutorial is designed for individuals with minimal statistical background. We will cover the basics of R, including how to install and load packages, import data, perform simple data manipulations, and create basic visualizations."
  },
  {
    "objectID": "content/01-basics.html#assignment-operator--",
    "href": "content/01-basics.html#assignment-operator--",
    "title": "Introduction to R: The Basics",
    "section": "Assignment Operator (<-)",
    "text": "Assignment Operator (&lt;-)\nThe assignment operator &lt;- is used to assign values to variables in R. It is considered more readable and is preferred over the = operator in the R community. There are debates regarding when we should use = instead of &lt;- but I am leaving that out of this tutorial for now.\n\nExample\n\n# Assigning value 10 to variable x\nx &lt;- 10\nx\n\n[1] 10"
  },
  {
    "objectID": "content/01-basics.html#pipe-operator",
    "href": "content/01-basics.html#pipe-operator",
    "title": "Introduction to R: The Basics",
    "section": "Pipe operator",
    "text": "Pipe operator\nThe pipe operator %&gt;%, heavily used in tidyverse packages, allows you to pass the result of one expression as the first argument to the next expression. It’s a powerful tool for chaining together a sequence of operations in a clear and concise manner. Instead of nesting functions or using intermediate variables, you can use the pipe operator to form a pipeline of operations.\n\nHow It Works\nConsider a simple example without the pipe operator:\n\nresult &lt;- sum(c(1, 2, 3, 4, 5))\nresult\n\n[1] 15\n\n\nWith the pipe operator, the same operation looks like this:\n\nc(1, 2, 3, 4, 5) %&gt;%\n  sum() \n\n[1] 15\n\n\nAlthough this is a simplistic example, it illustrates how %&gt;% passes the left-hand side of the operator as the first argument to the function on the right-hand side. This becomes particularly useful with functions from the dplyr package for data manipulation.\n\n\n\n\n\n\nRemember!\n\n\n\n“Piping” in R can be seen as “chaining.” This means that we are invoking multiple method calls.\n\n# Pipe\nrony %&gt;% \n  wake_up(time = \"5:30\") %&gt;% \n  get_out_of_bed() %&gt;% \n  do_exercise() %&gt;% \n  shower() %&gt;% \n  get_dressed() %&gt;% \n  eat(meal = \"breakfast\", coffee = TRUE) %&gt;% \n  brush_teeth() %&gt;%\n  work(effort = \"mininum\")\n\n# No pipe\n  work(\n    brush_teeth(\n      eat(\n        get_dressed(\n          shower(\n            do_exercise(\n              get_out_of_bed(\n                wake_up(rony, time = \"5:30\")\n              ), \n            )\n          )\n        ), meal = \"breakfast\", coffee = TRUE\n      )\n    ), effort = \"minimum\"\n  )"
  },
  {
    "objectID": "content/01-basics.html#subset-operators",
    "href": "content/01-basics.html#subset-operators",
    "title": "Introduction to R: The Basics",
    "section": "Subset Operators",
    "text": "Subset Operators\nR provides several operators for subsetting objects like vectors, lists, and data frames.\n\nThe [ ] Operator\nThe [ ] operator is used for extracting elements from vectors, matrices, or data frames based on their indices or conditions.\n\nExample with Vector\n\n# Creating a vector\nvec &lt;- c(1, 2, 3, 4, 5)\n\n# Subsetting the second element\nvec[2]\n\n[1] 2\n\n\n\n\nExample with Data Frame\n\n# Creating a data frame\ndf &lt;- data.frame(Name = c(\"Alice\", \"Bob\", \"Charlie\"), Age = c(25, 30, 35))\n\n# Subsetting rows\ndf[1:2, ]\n\n   Name Age\n1 Alice  25\n2   Bob  30\n\n\n\n\n\nThe [[ ]] Operator\nThe [[ ]] operator is used to extract elements from a list or a single element from a data frame, allowing for nested subsetting in lists.\n\nExample with List\n\n# Creating a list\nlst &lt;- list(name = \"Alice\", age = 25, scores = c(90, 80, 85))\n\n# Extracting a single element\nlst[[3]]\n\n[1] 90 80 85\n\n\n\n\n\nThe $ Operator\nThe $ operator is used for extracting elements by name from lists or data frames, making it particularly useful for accessing columns in a data frame.\n\nExample with Data Frame\n\n# Accessing a column by name\ndf$Name\n\n[1] \"Alice\"   \"Bob\"     \"Charlie\""
  },
  {
    "objectID": "content/02-data-cleaning.html#introduction",
    "href": "content/02-data-cleaning.html#introduction",
    "title": "Data Cleaning with the tidyverse",
    "section": "",
    "text": "Building on the basics of R and the tidyverse, this tutorial delves into more complex data cleaning and analysis techniques. We’ll tackle common challenges encountered with real-world data and explore ways to manipulate and analyze datasets to extract meaningful insights. But first, let’s see some differences between some data frames:\n\n\nIn the tidyverse, tibble() and tribble() are functions that create a more modern take on the data frame. They are part of the tibble package and offer several advantages over the base R data.frame for data analysis and manipulation (the one we saw in the basics tutorial. Here’s a brief overview of each and how they compare to traditional data frames.\n\n\n\nA tibble is a modern reimagining of the data frame, keeping what time has proven to be effective, and throwing out what is not. Here are some key features:\n\nPrinting: Tibbles are printed in a more readable format than traditional data frames, showing only the first 10 rows and all columns that fit on the screen.\nSubsetting: Subsetting a tibble with [ always returns a tibble, unlike data.frame, which might return a vector if a single column is selected.\nColumn data types: Tibbles are more tolerant about column types and do not convert strings to factors by default (a common source of frustration in R).\n\n\n# Creating a tibble\nmy_tibble &lt;- tibble(\n  id = 1:5,\n  name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\", \"Alex\"),\n  score = c(90, 80, 88, 100, 100)\n)\n\n\n\n\ntribble(), short for “transposed tibble”, is designed for easy manual creation of tibbles. It allows for a column-wise specification of data which can be more readable and convenient for small datasets or examples.\n\nReadability: The layout of tribble() makes it easy to visually match values to their respective columns.\nConvenience: Ideal for creating small datasets for examples or tests.\n\n\n# Creating a tribble\nmy_tribble &lt;- tribble(\n  ~id, ~name,    ~score,\n  1,   \"Emma\",  90,\n  2,   \"Rony\",  80,\n  3,   \"Jostin\", 88,\n  4,   \"David\",  100,\n  5,   \"Alex\",    100\n)\n\n\n\n\nWhile data.frame is the base R structure for storing tabular data, tibble and tribble bring improvements that are particularly useful in data analysis:\n\nPrinting and Viewing: Tibbles provide a more user-friendly way to view data in the console.\nFactor conversion: By default, strings are not converted to factors in tibbles, avoiding unexpected behavior during data analysis.\nSubsetting behavior: Consistent output types make tibble subsetting more predictable.\nRow names: Tibbles do not use row names, which encourages cleaner, more explicit data manipulation.\n\nIn summary, tibble() and tribble() offer a modern, tidyverse-optimized approach to data frames, making data manipulation and exploration in R more intuitive and less prone to common data analysis pitfalls."
  },
  {
    "objectID": "content/02-data-cleaning.html#counting-unique-categories",
    "href": "content/02-data-cleaning.html#counting-unique-categories",
    "title": "Data Cleaning with the tidyverse",
    "section": "Counting unique categories",
    "text": "Counting unique categories\nOne common task is to quantify how many times each category occurs within a dataset. This not only helps in identifying patterns or imbalances among categories but also aids in data preprocessing and cleaning by highlighting potential anomalies or errors in categorical data. In the following example, we will use the count() function on a dataframe data, targeting the category column. This approach enables us to efficiently count the number of occurrences of each unique value in the category column.\n\n# Counting (ocurrances) categories in the dataset.\ndata %&gt;% \n  count(category)\n\n# A tibble: 3 × 2\n  category     n\n  &lt;chr&gt;    &lt;int&gt;\n1 A            2\n2 B            2\n3 C            1\n\n\nThe distinct function allows us to identify unique values present in the category column.\n\n# Identifying unique values\ndata %&gt;%\n  distinct(category)\n\n# A tibble: 3 × 1\n  category\n  &lt;chr&gt;   \n1 A       \n2 B       \n3 C       \n\n\nFor a rapid tally of these unique values, the summarise function can be employed, utilizing n_distinct.\n\n# Tallying unique values\ndata %&gt;%\n  summarise(n = n_distinct(category))\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1     3\n\n\n\nImputing Missing Values\n\n# Impute missing values with the mean\ndata %&gt;% \n  mutate(\n    value = if_else(is.na(value), mean(value, na.rm = TRUE), value)\n  )\n\n# A tibble: 5 × 3\n     id value category\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1     1  3.33 A       \n2     2  5    B       \n3     3  2    A       \n4     4  3.33 B       \n5     5  3    C       \n\n\nHere, I use the mutate() function to modify the value column, where the if_else() function checks each element of value:\n\nif an element is missing (is.na(value) returns TRUE), it is replaced with the mean of the value column (computed with mean(value, na.rm = TRUE), where na.rm = TRUE ensures that missing values are ignored in the mean calculation);\nif not missing, the original value is retained. This approach is commonly used in data preprocessing to handle missing data by filling in missing values with the mean, thus maintaining the dataset’s size while addressing missingness without discarding any rows."
  },
  {
    "objectID": "content/03-data-wrangling.html",
    "href": "content/03-data-wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "In this tutorial, we delve into advanced data cleaning and analysis techniques focusing on student and department datasets. We will also demonstrate how to create custom functions in R to automate repetitive tasks in data analysis. We will delve into more sophisticated techniques such as reshaping data with pivot_wider and pivot_longer, and enhancing our data transformation skills with mutate across and the creation of custom functions. These methods are pivotal for preparing and analyzing data more effectively."
  },
  {
    "objectID": "content/03-data-wrangling.html#introduction",
    "href": "content/03-data-wrangling.html#introduction",
    "title": "Data Wrangling",
    "section": "",
    "text": "In this tutorial, we delve into advanced data cleaning and analysis techniques focusing on student and department datasets. We will also demonstrate how to create custom functions in R to automate repetitive tasks in data analysis. We will delve into more sophisticated techniques such as reshaping data with pivot_wider and pivot_longer, and enhancing our data transformation skills with mutate across and the creation of custom functions. These methods are pivotal for preparing and analyzing data more effectively."
  },
  {
    "objectID": "content/03-data-wrangling.html#reshaping-data",
    "href": "content/03-data-wrangling.html#reshaping-data",
    "title": "Data Wrangling",
    "section": "Reshaping Data",
    "text": "Reshaping Data\nReshaping data is a common task in data analysis that involves changing the structure of your data to make it more suitable for analysis. tidyverse provides two primary functions for this purpose: pivot_longer and pivot_wider.\n\nUsing pivot_longer\nWhen you have data in a wide format and want to make it longer, pivot_longer is your go-to function. It’s especially useful for converting multiple columns into key-value pairs, making the data tidy.\n\n# Sample wide data\nwide_data &lt;- tibble(\n  id = 1:3,\n  year_2018 = c(200, 150, 120),\n  year_2019 = c(220, 160, 130)\n)\n\n# Converting wide data to long format\nlong_data &lt;- wide_data %&gt;%\n  pivot_longer(\n    cols = starts_with(\"year\"),\n    names_to = \"year\",\n    values_to = \"value\"\n  )\nlong_data\n\n# A tibble: 6 × 3\n     id year      value\n  &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;\n1     1 year_2018   200\n2     1 year_2019   220\n3     2 year_2018   150\n4     2 year_2019   160\n5     3 year_2018   120\n6     3 year_2019   130\n\n\n\n\nUsing pivot_wider\nConversely, pivot_wider is used to spread a key-value pair across multiple columns, transforming longer data into a wider format. This is particularly useful for making data more readable or preparing it for certain types of analysis.\n\n# Converting back to wide format\nwider_data &lt;- long_data %&gt;%\n  pivot_wider(\n    names_from = year,\n    values_from = value\n  )\n\nwider_data\n\n# A tibble: 3 × 3\n     id year_2018 year_2019\n  &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1     1       200       220\n2     2       150       160\n3     3       120       130"
  },
  {
    "objectID": "content/03-data-wrangling.html#enhancing-data-transformation-with-mutate-and-custom-functions",
    "href": "content/03-data-wrangling.html#enhancing-data-transformation-with-mutate-and-custom-functions",
    "title": "Data Wrangling",
    "section": "Enhancing Data Transformation with mutate and Custom Functions",
    "text": "Enhancing Data Transformation with mutate and Custom Functions\n\nUsing mutate and across\nWith mutate across, you can apply a function across multiple columns at once, streamlining the process of data manipulation.\n\n# Applying a transformation across selected columns\ndata &lt;- tibble(\n  x1 = rnorm(5),\n  x2 = rnorm(5),\n  x3 = rnorm(5)\n)\n\n# Standardizing selected columns\ndata &lt;- data %&gt;%\n  mutate(\n    across(\n      starts_with(\"x\"), \n      ~(.x - mean(.x)) / sd(.x),\n      .names = \"std_{.col}\"\n    )\n  )\n\n\nmutate(): This function is used to add new columns or transform existing ones in a dataframe. Here, it is combined with the across() function to apply a transformation across multiple columns.\nacross(starts_with(\"x\"), ~(x. - mean(.x)) / sd(.x)): The across() function specifies which columns to operate on and the operation to perform:\n\nstarts_with(\"x\"): This argument selects all columns whose names start with “x”.\n~(.x - mean(.x)) / sd(.x): This formula calculates the z-score for each selected column. For each value in a column, it subtracts the mean of that column and then divides by the standard deviation of that column. The . symbol represents the current column’s values being processed.\nThe .names = \"std_{.col}\" argument in the across() function dynamically names new or transformed columns as std_ followed by the original column name, indicating they have been standardized.\n\n\nEssentially, the code standardizes the values of all columns in data that start with the letter “x”, ensuring they have a mean of 0 and a standard deviation of 1, then updates data with these standardized columns."
  },
  {
    "objectID": "content/03-data-wrangling.html#creating-functions-for-data-analysis",
    "href": "content/03-data-wrangling.html#creating-functions-for-data-analysis",
    "title": "Data Wrangling",
    "section": "Creating Functions for Data Analysis",
    "text": "Creating Functions for Data Analysis\nCreating custom functions can significantly enhance efficiency in data analysis. It might not be the case, but if you want to have a function that estimates the mean, sd, and std value in a column we can do the following. Let’s called it add_stats_columns. This function is designed to enhance a dataset by adding statistical analysis columns related to a specific numeric column within the dataset. It calculates the mean, standard deviation, and creates a standardized version of the selected column. Below is an explanation of the function and a breakdown of each line within it:\n\nThe add_stats_columns Function Explained\n\nadd_stats_columns &lt;- function(data, column_name) {\n  mean_val &lt;- mean(data[[column_name]], na.rm = TRUE)\n  sd_val   &lt;- sd(data[[column_name]], na.rm = TRUE)\n  \n  data[[paste0(column_name, \"_mean\")]] &lt;- mean_val\n  data[[paste0(column_name, \"_sd\")]]   &lt;- sd_val\n  data[[paste0(column_name, \"_standardized\")]] &lt;- (data[[column_name]] - mean_val) / sd_val\n  \n  return(data)\n}\n\n\nBreaking Down the Function\n\nadd_stats_columns &lt;- function(data, column_name) { ... }: This line defines the function add_stats_columns that takes two arguments: data, a dataset (in the form of a data frame or tibble), and column_name, a string representing the name of the column to be analyzed.\nmean_val &lt;- mean(data[[column_name]], na.rm = TRUE): This line calculates the mean of the specified column, excluding any NA (missing) values with na.rm = TRUE, and stores it in mean_val.\nsd_val &lt;- sd(data[[column_name]], na.rm = TRUE): Similarly, this line calculates the standard deviation of the specified column, excluding NA values, and stores it in sd_val.\ndata[[paste0(column_name, \"_mean\")]] &lt;- mean_val: This line creates a new column in the dataset named after the original column with _mean appended (e.g., if column_name is \"scores\", the new column name will be \"scores_mean\"), and assigns the calculated mean value to this new column for all rows.\ndata[[paste0(column_name, \"_sd\")]] &lt;- sd_val: This line adds another new column to the dataset for the standard deviation, following the same naming convention as for the mean (e.g., \"scores_sd\"), and fills it with the calculated standard deviation value.\ndata[[paste0(column_name, \"_standardized\")]] &lt;- (data[[column_name]] - mean_val) / sd_val: This line calculates the standardized value for each row in the specified column by subtracting the mean and dividing by the standard deviation. It then stores these values in a new column named with _standardized appended to the original column name (e.g., \"scores_standardized\"). Standardizing a dataset in this way adjusts the values to have a mean of 0 and a standard deviation of 1, which is useful for certain types of analysis and modeling.\nreturn(data): Finally, the function returns the modified dataset with the new statistical columns added. In fact, you can just write data, do not need to use the return function but let’s keep it.\n\n\n\n\nUsage Example\nAssuming students is a dataset with a numeric column named \"math_scores\", you can use the function to add statistical analysis columns related to \"math_scores\" as follows:\n\n# Example usage with a hypothetical numeric column in students dataset\n\n# Students data\nstudents &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  stu_name = c(\"Emma\", \"Rony\", \"Jostin\", \"David\"),\n  dept_id = c(2, 2, 3, 4)\n)\n\n# Let's merge a math_scores data first.\nscores &lt;- tibble(\n  stu_id = c(1, 2, 3, 4),\n  math_scores = c(80, 95, 93, 90)\n)\n\n# Merge the scores with the students data using stu_id \nstu_scores &lt;- right_join(students, scores, by = \"stu_id\")\nstu_scores\n\n# A tibble: 4 × 4\n  stu_id stu_name dept_id math_scores\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1      1 Emma           2          80\n2      2 Rony           2          95\n3      3 Jostin         3          93\n4      4 David          4          90\n\n# Now, let's apply the function add_stats_columns\nstu_scores_with_stats &lt;- add_stats_columns(stu_scores, \"math_scores\")\nstu_scores_with_stats\n\n# A tibble: 4 × 7\n  stu_id stu_name dept_id math_scores math_scores_mean math_scores_sd\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1      1 Emma           2          80             89.5           6.66\n2      2 Rony           2          95             89.5           6.66\n3      3 Jostin         3          93             89.5           6.66\n4      4 David          4          90             89.5           6.66\n# ℹ 1 more variable: math_scores_standardized &lt;dbl&gt;\n\n\n\n\nApplying Functions to Grouped Data\nUsing dplyr and purrr to apply functions to each group separately.\n\n# Group by department and apply stats function\nstudents_grouped &lt;- stu_scores %&gt;%\n  group_by(dept_id) %&gt;%\n  group_modify(~ add_stats_columns(.x, \"math_scores\")) %&gt;%\n  ungroup()\n\nstudents_grouped\n\n# A tibble: 4 × 7\n  dept_id stu_id stu_name math_scores math_scores_mean math_scores_sd\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1       2      1 Emma              80             87.5           10.6\n2       2      2 Rony              95             87.5           10.6\n3       3      3 Jostin            93             93             NA  \n4       4      4 David             90             90             NA  \n# ℹ 1 more variable: math_scores_standardized &lt;dbl&gt;\n\n\ngroup_modify() applies a function to each group of a grouped dataframe, where .x is the sliced dataframe for each group. This way, the add_stats_columns function is applied correctly to each department group within your stu_scores dataset.\nThis corrected approach ensures that your custom function add_stats_columns is applied to the math_scores column for each group defined by dept_id, achieving the intended goal of adding statistical columns based on department groups."
  },
  {
    "objectID": "content/04-data-viz.html",
    "href": "content/04-data-viz.html",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "Visualizing data is crucial in understanding underlying patterns and communicating results effectively. This tutorial will guide you through creating various types of visualizations using ggplot2 in R, focusing on a dataset of student scores (a fake dataset btw).\n\n\nFirst, we’ll load the dataset from a CSV file, and load the tidyverse package.\n\n# Load the package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the dataset\nscores_data &lt;- read_csv(\"../files/data/fake_scores.csv\")\n\nRows: 96 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): course, student, concentration\ndbl (2): studentid, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis dataset contains students (fake) information, you can use the glimpse function to look at the variables in the dataset. Table 1 shows a representation of the data we loaded as a table.\n\n\n\n\nTable 1: Data from the fake_scores.csv file as a table.\n\n\ncourse\nstudent\nstudentid\nscore\nconcentration\n\n\n\n\nEDU 001\nJostin\n1\n10\nEPPE\n\n\nEDU 001\nRony\n2\n6\nEPPE\n\n\nEDU 001\nJacob\n3\n87\nCIS\n\n\nEDU 001\nHwa\n4\n75\nCIS\n\n\nEDU 001\nEmma\n5\n19\nCIS\n\n\nEDU 001\nBen\n6\n9\nCIS\n\n\n\n\n\n\n\nglimpse(scores_data)\n\nRows: 96\nColumns: 5\n$ course        &lt;chr&gt; \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"…\n$ student       &lt;chr&gt; \"Jostin\", \"Rony\", \"Jacob\", \"Hwa\", \"Emma\", \"Ben\", \"Maddie…\n$ studentid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ score         &lt;dbl&gt; 10, 6, 87, 75, 19, 9, 40, 72, 97, 45, 33, 24, 24, 74, 69…\n$ concentration &lt;chr&gt; \"EPPE\", \"EPPE\", \"CIS\", \"CIS\", \"CIS\", \"CIS\", \"HDLT\", \"CIS…\n\n\n\n\n\nggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics. ggplot2 uses a grammar of graphics, where you define the data, aesthetics, and geometries.\n\n\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\n\nHistograms are great for visualizing the distribution of scores for a single subject. Let’s visualize the distribution of all scores in the dataset.\n\nscores_data %&gt;% \n  ggplot( \n    aes(x = score)\n  ) +\n  geom_histogram(\n    fill = \"grey\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribution of All Scores\",\n    x = \"All Scores\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nscores_data: The dataset being used, assumed to contain a column named score which holds the numeric values that we want to visualize.\n%&gt;%: The pipe operator, used here to pass scores_data as the first argument to the following ggplot() function.\nggplot(aes(x = score)): Initializes a ggplot object specifying the aesthetic mappings. Here, aes(x = score) indicates that the score column from scores_data should be used as the x-axis values in the histogram.\ngeom_histogram(): This adds a histogram layer to the plot.\nfill = \"grey\": Sets the fill color of the bars in the histogram to grey.\ncolor = \"black\": Sets the color of the border of the bars to black.\nlabs(): Used to modify the labels on the plot, including the title of the plot and the x and y axes. Here, it sets the title of the plot to “Distribution of All Scores”, labels the x-axis as “All Scores”, and the y-axis as “Count”, which represents the number of observations within each bin of scores.\ntheme_minimal(): Applies a minimalistic theme to the plot, which reduces the background clutter and focuses attention on the data itself.\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: The use of the + operator instead of the pipe operator (%&gt;%) in ggplot2 syntax is rooted in the design and philosophy of the ggplot2 package itself, which is based on the Grammar of Graphics.\n\nLayered Approach: ggplot2 is built on the concept of layering components of a plot on top of each other. The + operator is used to add or layer these components, such as axes, plot types (geoms), scales, and themes, to build up a plot step by step. This approach is akin to constructing a sentence in a language, where each layer adds more context or detail, aligning with the Grammar of Graphics philosophy.\n\n\n\n\n\n\nLet’s start with a scatter plot comparing scores across two subjects, assuming our dataset has Math and Science scores. However, see that your dataset currently is in long format. So, we need to change it to wide format. Look at the following code chunk:\n\nscores_data_wide &lt;- scores_data %&gt;% \n  filter(\n    course %in% c(\"EDU 001\", \"EDU 302\")\n  ) %&gt;% \n  pivot_wider(\n    names_from = course, \n    values_from = score\n  )\n\nscores_data_wide\n\n# A tibble: 24 × 5\n   student studentid concentration `EDU 001` `EDU 302`\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 Jostin          1 EPPE                 10         0\n 2 Rony            2 EPPE                  6        75\n 3 Jacob           3 CIS                  87         6\n 4 Hwa             4 CIS                  75        75\n 5 Emma            5 CIS                  19        48\n 6 Ben             6 CIS                   9         1\n 7 Maddie          7 HDLT                 40        89\n 8 Alex            8 CIS                  72        52\n 9 Krista          9 CIS                  97        61\n10 Max            10 HDLT                 45        15\n# ℹ 14 more rows\n\n\nThis will give a dataset with 24 observations and the two subject (EDU 001 and EDU 302) as columns.The pivot_wider function creates new columns for each course, with scores filled in accordingly.\n\nfilter(course %in% c(\"EDU 001\", \"EDU 302\")): Narrows down the dataset to only include scores from the specified courses.\npivot_wider(names_from = course, values_from = score): Transforms the dataset so each course becomes its own column, populated with corresponding scores.\n\nNow, let’s plot the scores in the two courses.\n\nscores_data_wide %&gt;% \n  ggplot(\n    aes(x = `EDU 001`, y = `EDU 302`)\n  ) +\n  geom_point() +\n  labs(\n    title = \"EDU 001 vs. EDU 302\",\n    x = \"EDU 001 Scores\",\n    y = \"EDU 302 Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nVisualizing data based on groups or categories is often insightful.\n\n\nUsing our dataset in long format, where each row represents a score in a specific course\n\nscores_data %&gt;% \n  ggplot(\n    aes(\n      x = course, \n      y = score, \n      fill = course\n    )\n  ) +\n  geom_boxplot() +\n  labs(\n    title = \"Scores by course\",\n    x = \"course\",\n    y = \"Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nA bar plot to visualize the average score per subject.\n\nscores_data %&gt;%\n  group_by(course) %&gt;%\n  summarise(\n    avg_score = mean(score)\n  ) %&gt;%\n  ggplot(\n    aes(\n      x = course, \n      y = avg_score, \n      fill = course\n    )\n  ) +\n  geom_col(color = \"black\") +\n  labs(\n    title = \"Average Scores by Course\",\n    x = \"Course\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis tutorial introduced basic to intermediate data visualization techniques using ggplot2 in R. By leveraging ggplot2’s comprehensive features, you can create informative and appealing visual representations of your data to aid in analysis and communication."
  },
  {
    "objectID": "content/04-data-viz.html#loading-the-dataset",
    "href": "content/04-data-viz.html#loading-the-dataset",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "First, we’ll load the dataset from a CSV file, and load the tidyverse package.\n\n# Load the package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the dataset\nscores_data &lt;- read_csv(\"../files/data/fake_scores.csv\")\n\nRows: 96 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): course, student, concentration\ndbl (2): studentid, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis dataset contains students (fake) information, you can use the glimpse function to look at the variables in the dataset. Table 1 shows a representation of the data we loaded as a table.\n\n\n\n\nTable 1: Data from the fake_scores.csv file as a table.\n\n\ncourse\nstudent\nstudentid\nscore\nconcentration\n\n\n\n\nEDU 001\nJostin\n1\n10\nEPPE\n\n\nEDU 001\nRony\n2\n6\nEPPE\n\n\nEDU 001\nJacob\n3\n87\nCIS\n\n\nEDU 001\nHwa\n4\n75\nCIS\n\n\nEDU 001\nEmma\n5\n19\nCIS\n\n\nEDU 001\nBen\n6\n9\nCIS\n\n\n\n\n\n\n\nglimpse(scores_data)\n\nRows: 96\nColumns: 5\n$ course        &lt;chr&gt; \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"…\n$ student       &lt;chr&gt; \"Jostin\", \"Rony\", \"Jacob\", \"Hwa\", \"Emma\", \"Ben\", \"Maddie…\n$ studentid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ score         &lt;dbl&gt; 10, 6, 87, 75, 19, 9, 40, 72, 97, 45, 33, 24, 24, 74, 69…\n$ concentration &lt;chr&gt; \"EPPE\", \"EPPE\", \"CIS\", \"CIS\", \"CIS\", \"CIS\", \"HDLT\", \"CIS…"
  },
  {
    "objectID": "content/04-data-viz.html#understanding-ggplot2",
    "href": "content/04-data-viz.html#understanding-ggplot2",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "ggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics. ggplot2 uses a grammar of graphics, where you define the data, aesthetics, and geometries.\n\n\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\n\nHistograms are great for visualizing the distribution of scores for a single subject. Let’s visualize the distribution of all scores in the dataset.\n\nscores_data %&gt;% \n  ggplot( \n    aes(x = score)\n  ) +\n  geom_histogram(\n    fill = \"grey\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribution of All Scores\",\n    x = \"All Scores\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nscores_data: The dataset being used, assumed to contain a column named score which holds the numeric values that we want to visualize.\n%&gt;%: The pipe operator, used here to pass scores_data as the first argument to the following ggplot() function.\nggplot(aes(x = score)): Initializes a ggplot object specifying the aesthetic mappings. Here, aes(x = score) indicates that the score column from scores_data should be used as the x-axis values in the histogram.\ngeom_histogram(): This adds a histogram layer to the plot.\nfill = \"grey\": Sets the fill color of the bars in the histogram to grey.\ncolor = \"black\": Sets the color of the border of the bars to black.\nlabs(): Used to modify the labels on the plot, including the title of the plot and the x and y axes. Here, it sets the title of the plot to “Distribution of All Scores”, labels the x-axis as “All Scores”, and the y-axis as “Count”, which represents the number of observations within each bin of scores.\ntheme_minimal(): Applies a minimalistic theme to the plot, which reduces the background clutter and focuses attention on the data itself.\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: The use of the + operator instead of the pipe operator (%&gt;%) in ggplot2 syntax is rooted in the design and philosophy of the ggplot2 package itself, which is based on the Grammar of Graphics.\n\nLayered Approach: ggplot2 is built on the concept of layering components of a plot on top of each other. The + operator is used to add or layer these components, such as axes, plot types (geoms), scales, and themes, to build up a plot step by step. This approach is akin to constructing a sentence in a language, where each layer adds more context or detail, aligning with the Grammar of Graphics philosophy.\n\n\n\n\n\n\nLet’s start with a scatter plot comparing scores across two subjects, assuming our dataset has Math and Science scores. However, see that your dataset currently is in long format. So, we need to change it to wide format. Look at the following code chunk:\n\nscores_data_wide &lt;- scores_data %&gt;% \n  filter(\n    course %in% c(\"EDU 001\", \"EDU 302\")\n  ) %&gt;% \n  pivot_wider(\n    names_from = course, \n    values_from = score\n  )\n\nscores_data_wide\n\n# A tibble: 24 × 5\n   student studentid concentration `EDU 001` `EDU 302`\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 Jostin          1 EPPE                 10         0\n 2 Rony            2 EPPE                  6        75\n 3 Jacob           3 CIS                  87         6\n 4 Hwa             4 CIS                  75        75\n 5 Emma            5 CIS                  19        48\n 6 Ben             6 CIS                   9         1\n 7 Maddie          7 HDLT                 40        89\n 8 Alex            8 CIS                  72        52\n 9 Krista          9 CIS                  97        61\n10 Max            10 HDLT                 45        15\n# ℹ 14 more rows\n\n\nThis will give a dataset with 24 observations and the two subject (EDU 001 and EDU 302) as columns.The pivot_wider function creates new columns for each course, with scores filled in accordingly.\n\nfilter(course %in% c(\"EDU 001\", \"EDU 302\")): Narrows down the dataset to only include scores from the specified courses.\npivot_wider(names_from = course, values_from = score): Transforms the dataset so each course becomes its own column, populated with corresponding scores.\n\nNow, let’s plot the scores in the two courses.\n\nscores_data_wide %&gt;% \n  ggplot(\n    aes(x = `EDU 001`, y = `EDU 302`)\n  ) +\n  geom_point() +\n  labs(\n    title = \"EDU 001 vs. EDU 302\",\n    x = \"EDU 001 Scores\",\n    y = \"EDU 302 Scores\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "content/04-data-viz.html#grouped-visualizations",
    "href": "content/04-data-viz.html#grouped-visualizations",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "Visualizing data based on groups or categories is often insightful.\n\n\nUsing our dataset in long format, where each row represents a score in a specific course\n\nscores_data %&gt;% \n  ggplot(\n    aes(\n      x = course, \n      y = score, \n      fill = course\n    )\n  ) +\n  geom_boxplot() +\n  labs(\n    title = \"Scores by course\",\n    x = \"course\",\n    y = \"Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nA bar plot to visualize the average score per subject.\n\nscores_data %&gt;%\n  group_by(course) %&gt;%\n  summarise(\n    avg_score = mean(score)\n  ) %&gt;%\n  ggplot(\n    aes(\n      x = course, \n      y = avg_score, \n      fill = course\n    )\n  ) +\n  geom_col(color = \"black\") +\n  labs(\n    title = \"Average Scores by Course\",\n    x = \"Course\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "content/04-data-viz.html#conclusion",
    "href": "content/04-data-viz.html#conclusion",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "This tutorial introduced basic to intermediate data visualization techniques using ggplot2 in R. By leveraging ggplot2’s comprehensive features, you can create informative and appealing visual representations of your data to aid in analysis and communication."
  },
  {
    "objectID": "content/05-data-summ.html",
    "href": "content/05-data-summ.html",
    "title": "Building Summary Statistics Tables",
    "section": "",
    "text": "modelsummary and gtsummary are two excellent r packages to build summary statistics. However, their syntax might not be fully intuitive if you are comming from Stata. Here are a couple of examples using these two packages.\nFirst, let’s load the following packages and load our data:\n\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(modelsummary)\nlibrary(haven)\n\ncensus &lt;- read_dta(\"http://www.stata-press.com/data/r9/census.dta\") %&gt;%\n  # Create dummy treatment\n  mutate(\n    rand = runif(n()),\n    treatment = as.numeric(rand &gt; 0.5)\n  )\n\nI’m using the census stata dta file for those who are familiar with this Stata dataset."
  },
  {
    "objectID": "content/05-data-summ.html#introduction",
    "href": "content/05-data-summ.html#introduction",
    "title": "Building Summary Statistics Tables",
    "section": "",
    "text": "modelsummary and gtsummary are two excellent r packages to build summary statistics. However, their syntax might not be fully intuitive if you are comming from Stata. Here are a couple of examples using these two packages.\nFirst, let’s load the following packages and load our data:\n\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(modelsummary)\nlibrary(haven)\n\ncensus &lt;- read_dta(\"http://www.stata-press.com/data/r9/census.dta\") %&gt;%\n  # Create dummy treatment\n  mutate(\n    rand = runif(n()),\n    treatment = as.numeric(rand &gt; 0.5)\n  )\n\nI’m using the census stata dta file for those who are familiar with this Stata dataset."
  },
  {
    "objectID": "content/05-data-summ.html#model-summary",
    "href": "content/05-data-summ.html#model-summary",
    "title": "Building Summary Statistics Tables",
    "section": "Model Summary",
    "text": "Model Summary\nWhen it comes to model summary, we have two approaches: (1) a rapid data summary, and (2) a more elaborated one. For the former, we use the datasummary_skim() function as follows:\n\ndatasummary_skim(census)\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\n\nCensus region\n4\n0\n2.7\n1.1\n1.0\n3.0\n4.0\n\n\n\npop\n50\n0\n4518149.4\n4715037.8\n401851.0\n3066433.0\n23667902.0\n\n\n\npoplt5\n50\n0\n326277.8\n331585.1\n35998.0\n227467.5\n1708400.0\n\n\n\npop5_17\n50\n0\n945951.6\n959372.8\n91796.0\n629654.0\n4680558.0\n\n\n\npop18p\n50\n0\n3245920.1\n3430531.3\n271106.0\n2175130.0\n17278944.0\n\n\n\npop65p\n50\n0\n509502.8\n538932.4\n11547.0\n370495.0\n2414250.0\n\n\n\npopurban\n50\n0\n3328253.2\n4090177.9\n172735.0\n2156905.0\n21607606.0\n\n\n\nmedage\n37\n0\n29.5\n1.7\n24.2\n29.8\n34.7\n\n\n\ndeath\n50\n0\n39474.3\n41742.3\n1604.0\n26176.5\n186428.0\n\n\n\nmarriage\n50\n0\n47701.4\n45130.4\n4437.0\n36279.0\n210864.0\n\n\n\ndivorce\n50\n0\n23679.4\n25094.0\n2142.0\n17112.5\n133541.0\n\n\n\nrand\n50\n0\n0.5\n0.3\n0.0\n0.5\n1.0\n\n\n\ntreatment\n2\n0\n0.5\n0.5\n0.0\n0.0\n1.0\n\n\n\n\n\n\n\n\nIf we want to select only a few variables, we could past a variables vector to the select function or create a new object with only the variables we need.\n\ncensus %&gt;%\n  select(pop, death, marriage, divorce) %&gt;%\n  datasummary_skim()\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\n\npop\n50\n0\n4518149.4\n4715037.8\n401851.0\n3066433.0\n23667902.0\n\n\n\ndeath\n50\n0\n39474.3\n41742.3\n1604.0\n26176.5\n186428.0\n\n\n\nmarriage\n50\n0\n47701.4\n45130.4\n4437.0\n36279.0\n210864.0\n\n\n\ndivorce\n50\n0\n23679.4\n25094.0\n2142.0\n17112.5\n133541.0\n\n\n\n\n\n\n\n\nIn addition, we can let the function knows if we would like to have only summary statistics for those variables that are either numeric or categorical, for example:\n\ndatasummary_skim(census, type = \"numeric\")\n\nIf we would like to have only the mean, sd, min, max instead of all the statistics that are presented using datasummary_skim we can use a 2-sided formula.\n\nbuild &lt;- pop + death + marriage + divorce ~ N + Mean + SD + Median + Min + Max \n\n## Without labels\n\ndatasummary(\n  build,\n  data = census\n) \n\n\n\n\n\nN\nMean\nSD\nMedian\nMin\nMax\n\n\n\n\npop\n50\n4518149.44\n4715037.75\n3066433.00\n401851.00\n23667902.00\n\n\ndeath\n50\n39474.26\n41742.35\n26176.50\n1604.00\n186428.00\n\n\nmarriage\n50\n47701.40\n45130.42\n36279.00\n4437.00\n210864.00\n\n\ndivorce\n50\n23679.44\n25094.01\n17112.50\n2142.00\n133541.00\n\n\n\n\n\n\n\nIn the case of variables labels, we will need to modify those variables names.\n\n## With labels\n\nbuild &lt;- `Population` + `Number of deaths` + `Number of marriages` + `Number of divorces` ~ N + Mean + SD + Median + Min + Max \n\ndatasummary(\n  build,\n  data = census %&gt;% \n    rename(`Population` = pop, `Number of deaths` = death, `Number of marriages` = marriage, `Number of divorces` = divorce)\n) \n\n\n\n\n\nN\nMean\nSD\nMedian\nMin\nMax\n\n\n\n\nPopulation\n50\n4518149.44\n4715037.75\n3066433.00\n401851.00\n23667902.00\n\n\nNumber of deaths\n50\n39474.26\n41742.35\n26176.50\n1604.00\n186428.00\n\n\nNumber of marriages\n50\n47701.40\n45130.42\n36279.00\n4437.00\n210864.00\n\n\nNumber of divorces\n50\n23679.44\n25094.01\n17112.50\n2142.00\n133541.00\n\n\n\n\n\n\n\nFinally, we can use the output argument to export our table to a several file formats.\n\nbuild &lt;- pop + death + marriage + divorce ~ N + Mean + SD + Median + Min + Max \n\ndatasummary(\n  build,\n  data = census,\n  output = \"latex\"\n) \n\nIn the case of latex, your output would like this and you can use the \\input command in your latex document to add your table to your reports or working papers:\n\n\\begin{table}\n  \\centering\n  \\begin{tabular}[t]{lrrrrrr}\n  \\toprule\n  & N & Mean & SD & Median & Min & Max\\\\\n  \\midrule\n  pop & 50 & \\num{4518149.44} & \\num{4715037.75} & \\num{3066433.00} & \\num{401851.00} & \\num{23667902.00}\\\\\n  death & 50 & \\num{39474.26} & \\num{41742.35} & \\num{26176.50} & \\num{1604.00} & \\num{186428.00}\\\\\n  marriage & 50 & \\num{47701.40} & \\num{45130.42} & \\num{36279.00} & \\num{4437.00} & \\num{210864.00}\\\\\n  divorce & 50 & \\num{23679.44} & \\num{25094.01} & \\num{17112.50} & \\num{2142.00} & \\num{133541.00}\\\\\n  \\bottomrule\n  \\end{tabular}\n\\end{table}\n\nCheck the official official vignette for more examples."
  },
  {
    "objectID": "content/05-data-summ.html#gt-summary",
    "href": "content/05-data-summ.html#gt-summary",
    "title": "Building Summary Statistics Tables",
    "section": "GT Summary",
    "text": "GT Summary\ngtsummary is another package that can be used for basic and complex summary statistics. Its syntax follows the gt family. For a basic summary statistics table, we can use the tbl_summary() function as follows:\n\nvars &lt;- c(\"pop\", \"death\", \"marriage\", \"divorce\")\n\ntab1 &lt;- census %&gt;% \n  select(all_of(vars)) %&gt;% \n  tbl_summary()\n\n\n\n\n\n\nBy treatment variable:\n\ntab2 &lt;- census %&gt;%\n  select(all_of(vars), treatment) %&gt;%\n  tbl_summary(by = treatment) %&gt;%\n  add_p()\n\n\n\n\n\n\nGiven that we would like to have a more econ-paper type of descriptive statistics, we can pass the columns we would like to have it in a vectorized way.\n\ncols &lt;- c(N = \"{N_nonmiss}\", Mean = \"{mean} ({sd})\", Median = \"{median}\", Min = \"{min}\", Max = \"{max}\")\ntab3 &lt;- cols %&gt;% \n  # we would go through each of these columns\n  imap(\n    ~ census %&gt;% \n      # and select the variables we need in our table\n      select(all_of(vars)) %&gt;% \n      tbl_summary(\n        statistic = all_continuous() ~ .x\n      ) %&gt;% \n      # We will modify the title of cols headers\n      modify_header(stat_0 ~ str_glue(\"{.y}\"), label ~ \"Variables\") \n  ) %&gt;% \n  # and merge every single of the columns into one single table\n  tbl_merge() %&gt;% \n  # remove spanning headers and footnote\n  modify_spanning_header(everything() ~ NA) %&gt;%\n  modify_footnote(everything() ~ NA) \n\n\n\n\n\n\nAnd, finally, we can use the as_kable_extra function to export our table to latex. The full example is here below:\n\ntab3 %&gt;%\n  as_kable_extra(\n    format = \"latex\", \n    booktabs = TRUE, \n    linesep = \"\"\n  )\n\n\n\n\nThat gives you the following latex code:\n\n\\begin{tabular}{lccccc}\n  \\toprule\n  Variables & N & Mean & Median & Min & Max\\\\\n  \\midrule\n  Population & 50 & 4,518,149 (4,715,038) & 3,066,433 & 401,851 & 23,667,902\\\\\n  Number of deaths & 50 & 39,474 (41,742) & 26,176 & 1,604 & 186,428\\\\\n  Number of marriages & 50 & 47,701 (45,130) & 36,279 & 4,437 & 210,864\\\\\n  Number of divorces & 50 & 23,679 (25,094) & 17,112 & 2,142 & 133,541\\\\\n  \\bottomrule\n\\end{tabular}\n\nCheck the official official vignette for more examples."
  },
  {
    "objectID": "content/05-data-summ.html#pdf-example",
    "href": "content/05-data-summ.html#pdf-example",
    "title": "Building Summary Statistics Tables",
    "section": "PDF Example",
    "text": "PDF Example\nA compiled PDF example of some of the tables that were created here can be found here"
  },
  {
    "objectID": "content/06-regex.html",
    "href": "content/06-regex.html",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Regular expressions are a powerful tool for pattern matching, searching, and replacing text. R, through the stringr package from the tidyverse, provides a suite of functions that make working with regular expressions straightforward.\n\n\nA regular expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains the specified search pattern.\n\n\n\n.: Matches any single character.\n^: Matches the start of a string.\n$: Matches the end of a string.\n*: Matches zero or more occurrences of the preceding element.\n+: Matches one or more occurrences of the preceding element.\n?: Matches zero or one occurrence of the preceding element.\n\\\\d: Matches any digits.\n\\\\w: Matches any word character (alphanumeric or underscore).\n[...]: Matches any single character contained within the brackets.\n|: Logical OR operator.\n\n\n\n\n\nThe stringr package simplifies the use of regular expressions in R. Here are some common functions:\n\n\nChecks if strings match a pattern.\n\ntexts &lt;- c(\"apple\", \"banana\", \"pear\", \"orange\")\nstr_detect(texts, pattern = \"a\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n\n\nExtracts the first occurrence of a pattern.\n\nstr_extract(texts, pattern = \"\\\\b[a-z]*a\\\\b\")\n\n[1] NA       \"banana\" NA       NA      \n\n\n\n\n\nReplaces the first occurrence of a pattern.\n\nstr_replace(texts, pattern = \"a\", replacement = \"@\")\n\n[1] \"@pple\"  \"b@nana\" \"pe@r\"   \"or@nge\"\n\n\n\n\n\nSplits strings based on a pattern.\n\nstr_split(texts, pattern = \"a\")\n\n[[1]]\n[1] \"\"     \"pple\"\n\n[[2]]\n[1] \"b\" \"n\" \"n\" \"\" \n\n[[3]]\n[1] \"pe\" \"r\" \n\n[[4]]\n[1] \"or\"  \"nge\"\n\n\n\n\n\n\n\n\nUsing a more complex regex to find email addresses in a string.\n\nsample_text &lt;- \"Contact us at info@example.com or support@example.org\"\nemail_pattern &lt;- \"[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,}\"\nstr_extract_all(sample_text, pattern = email_pattern)\n\n[[1]]\n[1] \"info@example.com\"    \"support@example.org\"\n\n\n\n\n\nCheck if strings are valid phone numbers.\n\nphone_numbers &lt;- c(\"123-456-7890\", \"987 654 3210\", \"Invalid Number\")\nphone_pattern &lt;- \"^\\\\d{3}[- ]?\\\\d{3}[- ]?\\\\d{4}$\"\nstr_detect(phone_numbers, pattern = phone_pattern)\n\n[1]  TRUE  TRUE FALSE\n\n\n\n\n\n\nRegular expressions are a versatile and powerful tool for text processing. The stringr package from the tidyverse makes regex operations in R both accessible and efficient. By mastering regular expressions, you can perform complex text manipulations and data cleaning tasks with ease."
  },
  {
    "objectID": "content/06-regex.html#basic-concepts",
    "href": "content/06-regex.html#basic-concepts",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "A regular expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains the specified search pattern.\n\n\n\n.: Matches any single character.\n^: Matches the start of a string.\n$: Matches the end of a string.\n*: Matches zero or more occurrences of the preceding element.\n+: Matches one or more occurrences of the preceding element.\n?: Matches zero or one occurrence of the preceding element.\n\\\\d: Matches any digits.\n\\\\w: Matches any word character (alphanumeric or underscore).\n[...]: Matches any single character contained within the brackets.\n|: Logical OR operator."
  },
  {
    "objectID": "content/06-regex.html#using-stringr-for-regex-operations",
    "href": "content/06-regex.html#using-stringr-for-regex-operations",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "The stringr package simplifies the use of regular expressions in R. Here are some common functions:\n\n\nChecks if strings match a pattern.\n\ntexts &lt;- c(\"apple\", \"banana\", \"pear\", \"orange\")\nstr_detect(texts, pattern = \"a\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n\n\nExtracts the first occurrence of a pattern.\n\nstr_extract(texts, pattern = \"\\\\b[a-z]*a\\\\b\")\n\n[1] NA       \"banana\" NA       NA      \n\n\n\n\n\nReplaces the first occurrence of a pattern.\n\nstr_replace(texts, pattern = \"a\", replacement = \"@\")\n\n[1] \"@pple\"  \"b@nana\" \"pe@r\"   \"or@nge\"\n\n\n\n\n\nSplits strings based on a pattern.\n\nstr_split(texts, pattern = \"a\")\n\n[[1]]\n[1] \"\"     \"pple\"\n\n[[2]]\n[1] \"b\" \"n\" \"n\" \"\" \n\n[[3]]\n[1] \"pe\" \"r\" \n\n[[4]]\n[1] \"or\"  \"nge\""
  },
  {
    "objectID": "content/06-regex.html#advanced-examples",
    "href": "content/06-regex.html#advanced-examples",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Using a more complex regex to find email addresses in a string.\n\nsample_text &lt;- \"Contact us at info@example.com or support@example.org\"\nemail_pattern &lt;- \"[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,}\"\nstr_extract_all(sample_text, pattern = email_pattern)\n\n[[1]]\n[1] \"info@example.com\"    \"support@example.org\"\n\n\n\n\n\nCheck if strings are valid phone numbers.\n\nphone_numbers &lt;- c(\"123-456-7890\", \"987 654 3210\", \"Invalid Number\")\nphone_pattern &lt;- \"^\\\\d{3}[- ]?\\\\d{3}[- ]?\\\\d{4}$\"\nstr_detect(phone_numbers, pattern = phone_pattern)\n\n[1]  TRUE  TRUE FALSE"
  },
  {
    "objectID": "content/06-regex.html#conclusion",
    "href": "content/06-regex.html#conclusion",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Regular expressions are a versatile and powerful tool for text processing. The stringr package from the tidyverse makes regex operations in R both accessible and efficient. By mastering regular expressions, you can perform complex text manipulations and data cleaning tasks with ease."
  },
  {
    "objectID": "content/04-data-analysis.html",
    "href": "content/04-data-analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "A note on reproducible research:\n\n\n\n\n\n\nRemember!\n\n\n\n\n\n\n Copy-pasting\n Manual formatting after exported\n\n\n\n\n R Markdown: dynamic document containing code and text that is exported directly from R into PDF, HTML, Word, Power Point and other formats\n LaTeX: typesetting system used for scientific publications that automatically reloads tables and figures every time the document is rendered\nWhat is NOT reproducible? Anything that requires manual steps to update results in your final document after you update the data or the exact specification. This includes the terrible practice of printing results in the console and pasting them into Word, but also the much less terrible practice of exporting results to Excel and then manually formatting them and copying into Word.\nThe two best options to combine with R in terms of reproducibility are Markdown and LaTeX. Markdown is R’s dyamic document framework and it’s amazingly well developed. Most R advanced R users actually use Markdown to display their results instead of exporting tables and figures. I’m going to show you what that looks like, but this is a slightly more advanced topic that will not be covered on this course.\nLaTeX, on the other hand, is widely used among non-R users, and there are plenty of packages to export tables to it in Stata as well.\nBut that’s enough of me talking. Let’s get you all to run some code\n\n\n\nWe will use the census data for this tutorial:\n\nthe census data that comes preloaded in Stata. For this, we are going to use the haven package.\nthe irony, right?\n\n\n# Load packages\nlibrary(tidyverse)\nlibrary(haven)\n\nExploratory Analysis:\nSummary statistics appear in almost every research product\n\nUsed to highlight central tendencies (means/medians)\nDescribe variation in data and comparison groups (SE/SD)\nIndicate ranges and outliers (quantiles and observation numbers)"
  },
  {
    "objectID": "content/04-data-analysis.html#introduction",
    "href": "content/04-data-analysis.html#introduction",
    "title": "Data Analysis",
    "section": "",
    "text": "A note on reproducible research:\n\n\n\n\n\n\nRemember!\n\n\n\n\n\n\n Copy-pasting\n Manual formatting after exported\n\n\n\n\n R Markdown: dynamic document containing code and text that is exported directly from R into PDF, HTML, Word, Power Point and other formats\n LaTeX: typesetting system used for scientific publications that automatically reloads tables and figures every time the document is rendered\nWhat is NOT reproducible? Anything that requires manual steps to update results in your final document after you update the data or the exact specification. This includes the terrible practice of printing results in the console and pasting them into Word, but also the much less terrible practice of exporting results to Excel and then manually formatting them and copying into Word.\nThe two best options to combine with R in terms of reproducibility are Markdown and LaTeX. Markdown is R’s dyamic document framework and it’s amazingly well developed. Most R advanced R users actually use Markdown to display their results instead of exporting tables and figures. I’m going to show you what that looks like, but this is a slightly more advanced topic that will not be covered on this course.\nLaTeX, on the other hand, is widely used among non-R users, and there are plenty of packages to export tables to it in Stata as well.\nBut that’s enough of me talking. Let’s get you all to run some code\n\n\n\nWe will use the census data for this tutorial:\n\nthe census data that comes preloaded in Stata. For this, we are going to use the haven package.\nthe irony, right?\n\n\n# Load packages\nlibrary(tidyverse)\nlibrary(haven)\n\nExploratory Analysis:\nSummary statistics appear in almost every research product\n\nUsed to highlight central tendencies (means/medians)\nDescribe variation in data and comparison groups (SE/SD)\nIndicate ranges and outliers (quantiles and observation numbers)"
  },
  {
    "objectID": "content/04-data-analysis.html#load-data",
    "href": "content/04-data-analysis.html#load-data",
    "title": "Data Analysis",
    "section": "Load data",
    "text": "Load data\nLet’s load and glimpse our data:\n\ncensus &lt;- read_dta(\"http://www.stata-press.com/data/r9/census.dta\")\nglimpse(census)\n\nRows: 50\nColumns: 12\n$ state    &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Co…\n$ region   &lt;dbl+lbl&gt; 3, 4, 4, 3, 4, 4, 1, 3, 3, 3, 4, 4, 2, 2, 2, 2, 3, 3, 1, …\n$ pop      &lt;dbl&gt; 3893888, 401851, 2718215, 2286435, 23667902, 2889964, 3107576…\n$ poplt5   &lt;dbl&gt; 296412, 38949, 213883, 175592, 1708400, 216495, 185188, 41151…\n$ pop5_17  &lt;dbl&gt; 865836, 91796, 577604, 495782, 4680558, 592318, 637731, 12544…\n$ pop18p   &lt;dbl&gt; 2731640, 271106, 1926728, 1615061, 17278944, 2081151, 2284657…\n$ pop65p   &lt;dbl&gt; 440015, 11547, 307362, 312477, 2414250, 247325, 364864, 59179…\n$ popurban &lt;dbl&gt; 2337713, 258567, 2278728, 1179556, 21607606, 2329869, 2449774…\n$ medage   &lt;dbl&gt; 29.3, 26.1, 29.2, 30.6, 29.9, 28.6, 32.0, 29.8, 34.7, 28.7, 2…\n$ death    &lt;dbl&gt; 35305, 1604, 21226, 22676, 186428, 18925, 26005, 5123, 104190…\n$ marriage &lt;dbl&gt; 49018, 5361, 30223, 26513, 210864, 34917, 26048, 4437, 108344…\n$ divorce  &lt;dbl&gt; 26745, 3517, 19908, 15882, 133541, 18571, 13488, 2313, 71579,…\n\n\nthe read_dta function allows us to load dta format data (Stata). It comes from the haven package.\n\n\n\n\n\n\nTip!\n\n\n\nWe can transform all “labelled” columns to factos in R using the following code:\n\ncensus &lt;- census %&gt;% \n    mutate(\n        across(\n            haven::is.labelled,\n            ~ as_factor(.x)\n        )\n    )\n\n\n\nLet’s say that you have selected the vars: pop, death, marriage, and divorce. Let’s select those variable and assigned to a new object and call it census2\n\ncensus &lt;- census %&gt;% \n  select(pop, death, marriage, divorce)"
  },
  {
    "objectID": "content/04-data-analysis.html#using-the-summary-function",
    "href": "content/04-data-analysis.html#using-the-summary-function",
    "title": "Data Analysis",
    "section": "Using the summary function",
    "text": "Using the summary function\n\nsummary(census)\n\n      pop               death           marriage         divorce      \n Min.   :  401851   Min.   :  1604   Min.   :  4437   Min.   :  2142  \n 1st Qu.: 1169218   1st Qu.:  9087   1st Qu.: 14840   1st Qu.:  6898  \n Median : 3066433   Median : 26177   Median : 36279   Median : 17113  \n Mean   : 4518149   Mean   : 39474   Mean   : 47701   Mean   : 23679  \n 3rd Qu.: 5434033   3rd Qu.: 46533   3rd Qu.: 57338   3rd Qu.: 27987  \n Max.   :23667902   Max.   :186428   Max.   :210864   Max.   :133541  \n\n\n\nsummary() can also be used with a single variable.\nWhen used with continuous variables, it works similarly to summarize in Stata.\nWhen used with categorical variables, it works similarly to tabulate.\n\nWith the same variables we selected before pop, death, marriage, and divorce. Let’s have the following stats: N, mean, sd, min, and max.\n\nsum_table &lt;- census %&gt;% \n    summarise(\n        n = sum(!is.na(pop)),\n        mean = mean(pop), \n        sd = sd(pop), \n        min = min(pop),\n        max = max(pop)\n    ) \n\n\n\n\n\n\nn\nmean\nsd\nmin\nmax\n\n\n\n\n50\n4518149\n4715038\n401851\n23667902"
  },
  {
    "objectID": "content/04-data-analysis.html#including-more-than-1-variable",
    "href": "content/04-data-analysis.html#including-more-than-1-variable",
    "title": "Data Analysis",
    "section": "Including more than 1 variable",
    "text": "Including more than 1 variable\nWe can also used across(), to include more variables. However, this will join more columns to the table we exported in the last exercise. Therefore, we need to transform, a little bit the output we get. * Can you detect any problem with the next code?\n\ncensus %&gt;% \n    summarise(\n        across(c(pop, marriage), \n            list(\n                n    = ~sum(!is.na(.x)),\n                mean = ~mean(.x), \n                sd   = ~sd(.x), \n                min  = ~min(.x),\n                max  = ~max(.x)\n            )\n        )\n    )\n\nThe last code will have 2 (variables) times 5 (stats) columns. We don’t want that. Therefore, let’s adjust it as follows:\n\nsum_table &lt;- census %&gt;% \n    summarise(\n        across(c(pop, marriage), \n            list(\n                n    = ~sum(!is.na(.x)),\n                mean = ~mean(.x), \n                sd   = ~sd(.x), \n                min  = ~min(.x),\n                max  = ~max(.x)\n            )\n        )\n    ) |&gt; \n    pivot_longer(everything()) %&gt;% #&lt;&lt;\n    separate(name, sep = \"_\", into = c(\"var\", \"stat\")) %&gt;% #&lt;&lt;\n    pivot_wider( #&lt;&lt;\n        names_from = \"stat\", values_from = \"value\" #&lt;&lt;\n    ) #&lt;&lt;\n\n\n\n\n\n\nvar\nn\nmean\nsd\nmin\nmax\n\n\n\n\npop\n50\n4518149.4\n4715037.75\n401851\n23667902\n\n\nmarriage\n50\n47701.4\n45130.42\n4437\n210864"
  },
  {
    "objectID": "content/04-data-analysis.html#descriptive-statistics-building-your-own-functions",
    "href": "content/04-data-analysis.html#descriptive-statistics-building-your-own-functions",
    "title": "Data Analysis",
    "section": "Descriptive statistics: building your own functions",
    "text": "Descriptive statistics: building your own functions\nIn tutorial 5, we will delve into more descriptive analysis but let’s try first to use the knowledge we have gained from the three first tutorials.\nLet’s create a function that is similar to the code we ran before:\n\nsum_fun &lt;- function(data, vars){\n    data |&gt; #&lt;&lt;\n        summarise(\n            across( {{vars}}, #&lt;&lt;\n                list(\n                    n    = ~sum(!is.na(.x)),\n                    mean = ~mean(.x), \n                    sd   = ~sd(.x), \n                    min  = ~min(.x),\n                    max  = ~max(.x)\n                )\n            )\n        ) |&gt; \n        pivot_longer(everything()) %&gt;% \n        separate(name, sep = \"_\", into = c(\"var\", \"stat\")) %&gt;% \n        pivot_wider(names_from = \"stat\", values_from = \"value\")\n}\n\nWith your new function sum_fun(), you can now call it anytime when you need it:\n\nsum_fun(census, c(pop, marriage, death))\n\n# A tibble: 3 × 6\n  var          n     mean       sd    min      max\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 pop         50 4518149. 4715038. 401851 23667902\n2 marriage    50   47701.   45130.   4437   210864\n3 death       50   39474.   41742.   1604   186428\n\n\n\n\n\n\n\nvar\nn\nmean\nsd\nmin\nmax\n\n\n\n\npop\n50\n4518149.44\n4715037.75\n401851\n23667902\n\n\nmarriage\n50\n47701.40\n45130.42\n4437\n210864\n\n\ndeath\n50\n39474.26\n41742.35\n1604\n186428"
  },
  {
    "objectID": "content/06-data-viz.html",
    "href": "content/06-data-viz.html",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "Visualizing data is crucial in understanding underlying patterns and communicating results effectively. This tutorial will guide you through creating various types of visualizations using ggplot2 in R, focusing on a dataset of student scores (a fake dataset btw).\n\n\nFirst, we’ll load the dataset from a CSV file, and load the tidyverse package.\n\n# Load the package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the dataset\nscores_data &lt;- read_csv(\"../files/data/fake_scores.csv\")\n\nRows: 96 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): course, student, concentration\ndbl (2): studentid, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis dataset contains students (fake) information, you can use the glimpse function to look at the variables in the dataset. Table 1 shows a representation of the data we loaded as a table.\n\n\n\n\nTable 1: Data from the fake_scores.csv file as a table.\n\n\ncourse\nstudent\nstudentid\nscore\nconcentration\n\n\n\n\nEDU 001\nJostin\n1\n10\nEPPE\n\n\nEDU 001\nRony\n2\n6\nEPPE\n\n\nEDU 001\nJacob\n3\n87\nCIS\n\n\nEDU 001\nHwa\n4\n75\nCIS\n\n\nEDU 001\nEmma\n5\n19\nCIS\n\n\nEDU 001\nBen\n6\n9\nCIS\n\n\n\n\n\n\n\nglimpse(scores_data)\n\nRows: 96\nColumns: 5\n$ course        &lt;chr&gt; \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"…\n$ student       &lt;chr&gt; \"Jostin\", \"Rony\", \"Jacob\", \"Hwa\", \"Emma\", \"Ben\", \"Maddie…\n$ studentid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ score         &lt;dbl&gt; 10, 6, 87, 75, 19, 9, 40, 72, 97, 45, 33, 24, 24, 74, 69…\n$ concentration &lt;chr&gt; \"EPPE\", \"EPPE\", \"CIS\", \"CIS\", \"CIS\", \"CIS\", \"HDLT\", \"CIS…\n\n\n\n\n\nggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics. ggplot2 uses a grammar of graphics, where you define the data, aesthetics, and geometries.\n\n\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\n\nHistograms are great for visualizing the distribution of scores for a single subject. Let’s visualize the distribution of all scores in the dataset.\n\nscores_data %&gt;% \n  ggplot( \n    aes(x = score)\n  ) +\n  geom_histogram(\n    fill = \"grey\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribution of All Scores\",\n    x = \"All Scores\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nscores_data: The dataset being used, assumed to contain a column named score which holds the numeric values that we want to visualize.\n%&gt;%: The pipe operator, used here to pass scores_data as the first argument to the following ggplot() function.\nggplot(aes(x = score)): Initializes a ggplot object specifying the aesthetic mappings. Here, aes(x = score) indicates that the score column from scores_data should be used as the x-axis values in the histogram.\ngeom_histogram(): This adds a histogram layer to the plot.\nfill = \"grey\": Sets the fill color of the bars in the histogram to grey.\ncolor = \"black\": Sets the color of the border of the bars to black.\nlabs(): Used to modify the labels on the plot, including the title of the plot and the x and y axes. Here, it sets the title of the plot to “Distribution of All Scores”, labels the x-axis as “All Scores”, and the y-axis as “Count”, which represents the number of observations within each bin of scores.\ntheme_minimal(): Applies a minimalistic theme to the plot, which reduces the background clutter and focuses attention on the data itself.\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: The use of the + operator instead of the pipe operator (%&gt;%) in ggplot2 syntax is rooted in the design and philosophy of the ggplot2 package itself, which is based on the Grammar of Graphics.\n\nLayered Approach: ggplot2 is built on the concept of layering components of a plot on top of each other. The + operator is used to add or layer these components, such as axes, plot types (geoms), scales, and themes, to build up a plot step by step. This approach is akin to constructing a sentence in a language, where each layer adds more context or detail, aligning with the Grammar of Graphics philosophy.\n\n\n\n\n\n\nLet’s start with a scatter plot comparing scores across two subjects, assuming our dataset has Math and Science scores. However, see that your dataset currently is in long format. So, we need to change it to wide format. Look at the following code chunk:\n\nscores_data_wide &lt;- scores_data %&gt;% \n  filter(\n    course %in% c(\"EDU 001\", \"EDU 302\")\n  ) %&gt;% \n  pivot_wider(\n    names_from = course, \n    values_from = score\n  )\n\nscores_data_wide\n\n# A tibble: 24 × 5\n   student studentid concentration `EDU 001` `EDU 302`\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 Jostin          1 EPPE                 10         0\n 2 Rony            2 EPPE                  6        75\n 3 Jacob           3 CIS                  87         6\n 4 Hwa             4 CIS                  75        75\n 5 Emma            5 CIS                  19        48\n 6 Ben             6 CIS                   9         1\n 7 Maddie          7 HDLT                 40        89\n 8 Alex            8 CIS                  72        52\n 9 Krista          9 CIS                  97        61\n10 Max            10 HDLT                 45        15\n# ℹ 14 more rows\n\n\nThis will give a dataset with 24 observations and the two subject (EDU 001 and EDU 302) as columns.The pivot_wider function creates new columns for each course, with scores filled in accordingly.\n\nfilter(course %in% c(\"EDU 001\", \"EDU 302\")): Narrows down the dataset to only include scores from the specified courses.\npivot_wider(names_from = course, values_from = score): Transforms the dataset so each course becomes its own column, populated with corresponding scores.\n\nNow, let’s plot the scores in the two courses.\n\nscores_data_wide %&gt;% \n  ggplot(\n    aes(x = `EDU 001`, y = `EDU 302`)\n  ) +\n  geom_point() +\n  labs(\n    title = \"EDU 001 vs. EDU 302\",\n    x = \"EDU 001 Scores\",\n    y = \"EDU 302 Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nVisualizing data based on groups or categories is often insightful.\n\n\nUsing our dataset in long format, where each row represents a score in a specific course\n\nscores_data %&gt;% \n  ggplot(\n    aes(\n      x = course, \n      y = score, \n      fill = course\n    )\n  ) +\n  geom_boxplot() +\n  labs(\n    title = \"Scores by course\",\n    x = \"course\",\n    y = \"Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nA bar plot to visualize the average score per subject.\n\nscores_data %&gt;%\n  group_by(course) %&gt;%\n  summarise(\n    avg_score = mean(score)\n  ) %&gt;%\n  ggplot(\n    aes(\n      x = course, \n      y = avg_score, \n      fill = course\n    )\n  ) +\n  geom_col(color = \"black\") +\n  labs(\n    title = \"Average Scores by Course\",\n    x = \"Course\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis tutorial introduced basic to intermediate data visualization techniques using ggplot2 in R. By leveraging ggplot2’s comprehensive features, you can create informative and appealing visual representations of your data to aid in analysis and communication."
  },
  {
    "objectID": "content/06-data-viz.html#loading-the-dataset",
    "href": "content/06-data-viz.html#loading-the-dataset",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "First, we’ll load the dataset from a CSV file, and load the tidyverse package.\n\n# Load the package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the dataset\nscores_data &lt;- read_csv(\"../files/data/fake_scores.csv\")\n\nRows: 96 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): course, student, concentration\ndbl (2): studentid, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis dataset contains students (fake) information, you can use the glimpse function to look at the variables in the dataset. Table 1 shows a representation of the data we loaded as a table.\n\n\n\n\nTable 1: Data from the fake_scores.csv file as a table.\n\n\ncourse\nstudent\nstudentid\nscore\nconcentration\n\n\n\n\nEDU 001\nJostin\n1\n10\nEPPE\n\n\nEDU 001\nRony\n2\n6\nEPPE\n\n\nEDU 001\nJacob\n3\n87\nCIS\n\n\nEDU 001\nHwa\n4\n75\nCIS\n\n\nEDU 001\nEmma\n5\n19\nCIS\n\n\nEDU 001\nBen\n6\n9\nCIS\n\n\n\n\n\n\n\nglimpse(scores_data)\n\nRows: 96\nColumns: 5\n$ course        &lt;chr&gt; \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"EDU 001\", \"…\n$ student       &lt;chr&gt; \"Jostin\", \"Rony\", \"Jacob\", \"Hwa\", \"Emma\", \"Ben\", \"Maddie…\n$ studentid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ score         &lt;dbl&gt; 10, 6, 87, 75, 19, 9, 40, 72, 97, 45, 33, 24, 24, 74, 69…\n$ concentration &lt;chr&gt; \"EPPE\", \"EPPE\", \"CIS\", \"CIS\", \"CIS\", \"CIS\", \"HDLT\", \"CIS…"
  },
  {
    "objectID": "content/06-data-viz.html#understanding-ggplot2",
    "href": "content/06-data-viz.html#understanding-ggplot2",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "ggplot2 is a part of the tidyverse that allows for creating complex and beautiful visualizations using a consistent and intuitive syntax. The name ggplot2 is derived from the concept of the grammar of graphics, a system for describing and building a wide range of graphics. ggplot2 uses a grammar of graphics, where you define the data, aesthetics, and geometries.\n\n\nA ggplot2 graph is built up from a few basic elements:\n\nData: The dataset you want to visualize.\nAesthetics (aes): Defines how variables in the data are mapped to visual properties (aesthetics) of the graph such as x and y axes, color, size, etc.\nGeometries (geom_ functions): The geometric objects (shapes) that represent the data points. For example, points (geom_point() for scatter plots), lines (geom_line()), and bars (geom_bar() for bar charts).\n\n\n\n\nHistograms are great for visualizing the distribution of scores for a single subject. Let’s visualize the distribution of all scores in the dataset.\n\nscores_data %&gt;% \n  ggplot( \n    aes(x = score)\n  ) +\n  geom_histogram(\n    fill = \"grey\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribution of All Scores\",\n    x = \"All Scores\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nscores_data: The dataset being used, assumed to contain a column named score which holds the numeric values that we want to visualize.\n%&gt;%: The pipe operator, used here to pass scores_data as the first argument to the following ggplot() function.\nggplot(aes(x = score)): Initializes a ggplot object specifying the aesthetic mappings. Here, aes(x = score) indicates that the score column from scores_data should be used as the x-axis values in the histogram.\ngeom_histogram(): This adds a histogram layer to the plot.\nfill = \"grey\": Sets the fill color of the bars in the histogram to grey.\ncolor = \"black\": Sets the color of the border of the bars to black.\nlabs(): Used to modify the labels on the plot, including the title of the plot and the x and y axes. Here, it sets the title of the plot to “Distribution of All Scores”, labels the x-axis as “All Scores”, and the y-axis as “Count”, which represents the number of observations within each bin of scores.\ntheme_minimal(): Applies a minimalistic theme to the plot, which reduces the background clutter and focuses attention on the data itself.\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: The use of the + operator instead of the pipe operator (%&gt;%) in ggplot2 syntax is rooted in the design and philosophy of the ggplot2 package itself, which is based on the Grammar of Graphics.\n\nLayered Approach: ggplot2 is built on the concept of layering components of a plot on top of each other. The + operator is used to add or layer these components, such as axes, plot types (geoms), scales, and themes, to build up a plot step by step. This approach is akin to constructing a sentence in a language, where each layer adds more context or detail, aligning with the Grammar of Graphics philosophy.\n\n\n\n\n\n\nLet’s start with a scatter plot comparing scores across two subjects, assuming our dataset has Math and Science scores. However, see that your dataset currently is in long format. So, we need to change it to wide format. Look at the following code chunk:\n\nscores_data_wide &lt;- scores_data %&gt;% \n  filter(\n    course %in% c(\"EDU 001\", \"EDU 302\")\n  ) %&gt;% \n  pivot_wider(\n    names_from = course, \n    values_from = score\n  )\n\nscores_data_wide\n\n# A tibble: 24 × 5\n   student studentid concentration `EDU 001` `EDU 302`\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 Jostin          1 EPPE                 10         0\n 2 Rony            2 EPPE                  6        75\n 3 Jacob           3 CIS                  87         6\n 4 Hwa             4 CIS                  75        75\n 5 Emma            5 CIS                  19        48\n 6 Ben             6 CIS                   9         1\n 7 Maddie          7 HDLT                 40        89\n 8 Alex            8 CIS                  72        52\n 9 Krista          9 CIS                  97        61\n10 Max            10 HDLT                 45        15\n# ℹ 14 more rows\n\n\nThis will give a dataset with 24 observations and the two subject (EDU 001 and EDU 302) as columns.The pivot_wider function creates new columns for each course, with scores filled in accordingly.\n\nfilter(course %in% c(\"EDU 001\", \"EDU 302\")): Narrows down the dataset to only include scores from the specified courses.\npivot_wider(names_from = course, values_from = score): Transforms the dataset so each course becomes its own column, populated with corresponding scores.\n\nNow, let’s plot the scores in the two courses.\n\nscores_data_wide %&gt;% \n  ggplot(\n    aes(x = `EDU 001`, y = `EDU 302`)\n  ) +\n  geom_point() +\n  labs(\n    title = \"EDU 001 vs. EDU 302\",\n    x = \"EDU 001 Scores\",\n    y = \"EDU 302 Scores\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "content/06-data-viz.html#grouped-visualizations",
    "href": "content/06-data-viz.html#grouped-visualizations",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "Visualizing data based on groups or categories is often insightful.\n\n\nUsing our dataset in long format, where each row represents a score in a specific course\n\nscores_data %&gt;% \n  ggplot(\n    aes(\n      x = course, \n      y = score, \n      fill = course\n    )\n  ) +\n  geom_boxplot() +\n  labs(\n    title = \"Scores by course\",\n    x = \"course\",\n    y = \"Scores\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nA bar plot to visualize the average score per subject.\n\nscores_data %&gt;%\n  group_by(course) %&gt;%\n  summarise(\n    avg_score = mean(score)\n  ) %&gt;%\n  ggplot(\n    aes(\n      x = course, \n      y = avg_score, \n      fill = course\n    )\n  ) +\n  geom_col(color = \"black\") +\n  labs(\n    title = \"Average Scores by Course\",\n    x = \"Course\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "content/06-data-viz.html#conclusion",
    "href": "content/06-data-viz.html#conclusion",
    "title": "Data Visualization in R using ggplot2",
    "section": "",
    "text": "This tutorial introduced basic to intermediate data visualization techniques using ggplot2 in R. By leveraging ggplot2’s comprehensive features, you can create informative and appealing visual representations of your data to aid in analysis and communication."
  },
  {
    "objectID": "content/07-regex.html",
    "href": "content/07-regex.html",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Regular expressions are a powerful tool for pattern matching, searching, and replacing text. R, through the stringr package from the tidyverse, provides a suite of functions that make working with regular expressions straightforward.\n\n\nA regular expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains the specified search pattern.\n\n\n\n.: Matches any single character.\n^: Matches the start of a string.\n$: Matches the end of a string.\n*: Matches zero or more occurrences of the preceding element.\n+: Matches one or more occurrences of the preceding element.\n?: Matches zero or one occurrence of the preceding element.\n\\\\d: Matches any digits.\n\\\\w: Matches any word character (alphanumeric or underscore).\n[...]: Matches any single character contained within the brackets.\n|: Logical OR operator.\n\n\n\n\n\nThe stringr package simplifies the use of regular expressions in R. Here are some common functions:\n\n\nChecks if strings match a pattern.\n\ntexts &lt;- c(\"apple\", \"banana\", \"pear\", \"orange\")\nstr_detect(texts, pattern = \"a\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n\n\nExtracts the first occurrence of a pattern.\n\nstr_extract(texts, pattern = \"\\\\b[a-z]*a\\\\b\")\n\n[1] NA       \"banana\" NA       NA      \n\n\n\n\n\nReplaces the first occurrence of a pattern.\n\nstr_replace(texts, pattern = \"a\", replacement = \"@\")\n\n[1] \"@pple\"  \"b@nana\" \"pe@r\"   \"or@nge\"\n\n\n\n\n\nSplits strings based on a pattern.\n\nstr_split(texts, pattern = \"a\")\n\n[[1]]\n[1] \"\"     \"pple\"\n\n[[2]]\n[1] \"b\" \"n\" \"n\" \"\" \n\n[[3]]\n[1] \"pe\" \"r\" \n\n[[4]]\n[1] \"or\"  \"nge\"\n\n\n\n\n\n\n\n\nUsing a more complex regex to find email addresses in a string.\n\nsample_text &lt;- \"Contact us at info@example.com or support@example.org\"\nemail_pattern &lt;- \"[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,}\"\nstr_extract_all(sample_text, pattern = email_pattern)\n\n[[1]]\n[1] \"info@example.com\"    \"support@example.org\"\n\n\n\n\n\nCheck if strings are valid phone numbers.\n\nphone_numbers &lt;- c(\"123-456-7890\", \"987 654 3210\", \"Invalid Number\")\nphone_pattern &lt;- \"^\\\\d{3}[- ]?\\\\d{3}[- ]?\\\\d{4}$\"\nstr_detect(phone_numbers, pattern = phone_pattern)\n\n[1]  TRUE  TRUE FALSE\n\n\n\n\n\n\nRegular expressions are a versatile and powerful tool for text processing. The stringr package from the tidyverse makes regex operations in R both accessible and efficient. By mastering regular expressions, you can perform complex text manipulations and data cleaning tasks with ease."
  },
  {
    "objectID": "content/07-regex.html#basic-concepts",
    "href": "content/07-regex.html#basic-concepts",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "A regular expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains the specified search pattern.\n\n\n\n.: Matches any single character.\n^: Matches the start of a string.\n$: Matches the end of a string.\n*: Matches zero or more occurrences of the preceding element.\n+: Matches one or more occurrences of the preceding element.\n?: Matches zero or one occurrence of the preceding element.\n\\\\d: Matches any digits.\n\\\\w: Matches any word character (alphanumeric or underscore).\n[...]: Matches any single character contained within the brackets.\n|: Logical OR operator."
  },
  {
    "objectID": "content/07-regex.html#using-stringr-for-regex-operations",
    "href": "content/07-regex.html#using-stringr-for-regex-operations",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "The stringr package simplifies the use of regular expressions in R. Here are some common functions:\n\n\nChecks if strings match a pattern.\n\ntexts &lt;- c(\"apple\", \"banana\", \"pear\", \"orange\")\nstr_detect(texts, pattern = \"a\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n\n\nExtracts the first occurrence of a pattern.\n\nstr_extract(texts, pattern = \"\\\\b[a-z]*a\\\\b\")\n\n[1] NA       \"banana\" NA       NA      \n\n\n\n\n\nReplaces the first occurrence of a pattern.\n\nstr_replace(texts, pattern = \"a\", replacement = \"@\")\n\n[1] \"@pple\"  \"b@nana\" \"pe@r\"   \"or@nge\"\n\n\n\n\n\nSplits strings based on a pattern.\n\nstr_split(texts, pattern = \"a\")\n\n[[1]]\n[1] \"\"     \"pple\"\n\n[[2]]\n[1] \"b\" \"n\" \"n\" \"\" \n\n[[3]]\n[1] \"pe\" \"r\" \n\n[[4]]\n[1] \"or\"  \"nge\""
  },
  {
    "objectID": "content/07-regex.html#advanced-examples",
    "href": "content/07-regex.html#advanced-examples",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Using a more complex regex to find email addresses in a string.\n\nsample_text &lt;- \"Contact us at info@example.com or support@example.org\"\nemail_pattern &lt;- \"[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,}\"\nstr_extract_all(sample_text, pattern = email_pattern)\n\n[[1]]\n[1] \"info@example.com\"    \"support@example.org\"\n\n\n\n\n\nCheck if strings are valid phone numbers.\n\nphone_numbers &lt;- c(\"123-456-7890\", \"987 654 3210\", \"Invalid Number\")\nphone_pattern &lt;- \"^\\\\d{3}[- ]?\\\\d{3}[- ]?\\\\d{4}$\"\nstr_detect(phone_numbers, pattern = phone_pattern)\n\n[1]  TRUE  TRUE FALSE"
  },
  {
    "objectID": "content/07-regex.html#conclusion",
    "href": "content/07-regex.html#conclusion",
    "title": "Regular Expressions in R with tidyverse",
    "section": "",
    "text": "Regular expressions are a versatile and powerful tool for text processing. The stringr package from the tidyverse makes regex operations in R both accessible and efficient. By mastering regular expressions, you can perform complex text manipulations and data cleaning tasks with ease."
  },
  {
    "objectID": "content/01-basics-stata.html",
    "href": "content/01-basics-stata.html",
    "title": "Introduction to Stata: The Basics",
    "section": "",
    "text": "In construction!"
  },
  {
    "objectID": "content/01-basics-stata.html#introduction",
    "href": "content/01-basics-stata.html#introduction",
    "title": "Introduction to Stata: The Basics",
    "section": "",
    "text": "In construction!"
  }
]